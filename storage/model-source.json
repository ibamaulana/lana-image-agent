{
  "fetchedAt": "2025-11-17T10:59:46.404Z",
  "totalModels": 36,
  "models": [
    {
      "id": "image-01",
      "name": "image-01",
      "owner": "minimax",
      "fullName": "minimax/image-01",
      "createdAt": "2025-03-03T14:05:29.816962Z",
      "runCount": 2029804,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_cover_image/926994db-2c8e-4b7d-934f-2f86b2480e55/43b05178-4b2a-42d9-9130-4fedae65.webp",
      "url": "https://replicate.com/minimax/image-01",
      "inputSchema": {
        "prompt": {
          "type": "string",
          "description": "Text prompt for generation",
          "required": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Image aspect ratio",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "number_of_images": {
          "type": "integer",
          "description": "Number of images to generate",
          "required": false,
          "default": 1,
          "isImageInput": true
        },
        "prompt_optimizer": {
          "type": "boolean",
          "description": "Use prompt optimizer",
          "required": false,
          "default": true
        },
        "subject_reference": {
          "type": "string",
          "description": "An optional character reference image (human face) to use as the subject in the generated image(s).",
          "required": false,
          "format": "uri",
          "isImageInput": true
        }
      },
      "readme": "# MiniMax Image-01\r\n\r\nMiniMax Image-01 is a text-to-image generation model with support for generating people based on a reference image.\r\n\r\n## Features\r\n\r\n### Prompt Control\r\n\r\n- High prompt-to-image fidelity\r\n- Logical consistency in generated results\r\n\r\n### Visual Quality\r\n\r\n- Detailed lighting and shadow effects\r\n- Rich environmental details\r\n- Complex scene composition\r\n\r\n### Subject Rendering\r\n\r\n- Realistic human subjects with natural textures and expressions\r\n- Detailed object rendering with accurate material properties\r\n\r\n## Privacy policy\r\n\r\nData from this model is sent from Replicate to MiniMax.\r\n\r\nCheck their Privacy Policy for details:\r\n\r\nhttps://intl.minimaxi.com/protocol/privacy-policy\r\n\r\n## Terms of Service\r\n\r\nhttps://intl.minimaxi.com/protocol/terms-of-service"
    },
    {
      "id": "seedream-3",
      "name": "seedream-3",
      "owner": "bytedance",
      "fullName": "bytedance/seedream-3",
      "createdAt": "2025-06-25T09:52:01.536291Z",
      "runCount": 2878239,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/de2ae1dd-f7b8-4b9e-901e-86125ac2b4a8/tmpcoezojc2.jpg",
      "url": "https://replicate.com/bytedance/seedream-3",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "size": {
          "type": "string",
          "description": "Big images will have their longest dimension be 2048px. Small images will have their shortest dimension be 512px. Regular images will always be 1 megapixel. Ignored if aspect ratio is custom.",
          "required": false,
          "default": "regular",
          "isImageInput": true
        },
        "width": {
          "type": "integer",
          "description": "Image width",
          "required": false,
          "default": 2048,
          "isImageInput": true
        },
        "height": {
          "type": "integer",
          "description": "Image height",
          "required": false,
          "default": 2048,
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Image aspect ratio. Set to 'custom' to specify width and height.",
          "required": false,
          "default": "16:9",
          "isImageInput": true
        },
        "guidance_scale": {
          "type": "number",
          "description": "Prompt adherence. Higher = more literal.",
          "required": false,
          "default": 2.5
        }
      },
      "readme": "# Seedream-3.0 (text-to-image)\r\n\r\nSeedream 3.0 is a bilingual (Chinese and English) text-to-image model developed by ByteDance's large model team, supporting native high-resolution image generation. Seedream 3.0 offers significant improvements: native 2K resolution output, faster response times, more accurate small text generation, enhanced text layout, strong instruction following, improved aesthetics and structure, and better fidelity and detail. It leads in multiple evaluations and can be applied to more complex and diverse image generation scenarios.\r\n\r\n## Capabilities\r\n\r\nWith significantly improved overall capabilities, the model leads the field. It excels in text-image alignment, composition, and aesthetic quality, consistently ranking first in benchmarks such as EvalMuse, HPSv2, and MPS.\r\n\r\nExceptional Text Layout for Visually Stunning Results: The model excels at generating small and large text, particularly in Chinese and English, with high accuracy and aesthetically pleasing layouts. Easily create designer-quality posters incorporating diverse fonts, styles, and layouts, surpassing even the human-designed templates of platforms like Canva.\r\n\r\nImmersive Visuals with Photorealistic Portraits and Cinematic Beauty: Experience significantly enhanced image aesthetics, especially in cinematic scenes. Generated portraits are more realistic with improved skin and hair textures and highly detailed clothing.\r\n\r\nEfficient Generation with Native 2K High Resolution: Generate images in native 2K resolution with various aspect ratios, eliminating the need for post-processing. Leveraging multiple model acceleration techniques, a 1K image can be generated in just 3 seconds, significantly faster than other models.\r\n\r\n## Applications\r\n\r\nSeedream 3.0 has broad applications across e-commerce, gaming, film and television, animation, and design, revolutionizing traditional content creation and dramatically increasing the efficiency of visual content production."
    },
    {
      "id": "photon",
      "name": "photon",
      "owner": "luma",
      "fullName": "luma/photon",
      "createdAt": "2024-12-05T15:17:52.527323Z",
      "runCount": 2998290,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/74be8de0-7f2e-4db9-8bf5-4eb208f4f50a/replicate-prediction-9_4J6lsXk.jpg",
      "url": "https://replicate.com/luma/photon",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "16:9",
          "isImageInput": true
        },
        "image_reference_url": {
          "type": "string",
          "description": "URL of a reference image to guide generation",
          "required": false,
          "isImageInput": true
        },
        "style_reference_url": {
          "type": "string",
          "description": "URL of a style reference image",
          "required": false,
          "isImageInput": true
        },
        "image_reference_weight": {
          "type": "number",
          "description": "Weight of the reference image. Larger values will make the reference image have a stronger influence on the generated image.",
          "required": false,
          "default": 0.85,
          "isImageInput": true
        },
        "style_reference_weight": {
          "type": "number",
          "description": "Weight of the style reference image",
          "required": false,
          "default": 0.85,
          "isImageInput": true
        },
        "character_reference_url": {
          "type": "string",
          "description": "URL of a character reference image",
          "required": false,
          "isImageInput": true
        }
      },
      "readme": "# Luma Photon\r\n\r\nA high-efficiency image generation model with enhanced creative capabilities and natural language understanding.\r\n\r\nhttps://lumalabs.ai/photon\r\n\r\n## Models\r\n\r\n- **Luma Photon**: Standard model optimized for quality\r\n- **Photon Flash**: High-speed variant optimized for efficiency\r\n\r\n## Key Capabilities\r\n\r\n- Advanced natural language understanding\r\n- Multi-turn iterative workflows\r\n- Character consistency from single reference images\r\n- Multi-image reference system\r\n- High prompt adherence\r\n\r\n## Technical Specifications\r\n\r\n### Performance Metrics\r\n\r\n- Outperforms existing models in blind evaluation tests\r\n- Specialized evaluation framework for creative use cases\r\n- Significantly improved efficiency compared to similar models\r\n\r\n### Architecture Features\r\n\r\n- Large context window for image generation\r\n- New architectural design optimized for efficiency\r\n- Enhanced reference image processing system\r\n\r\n## Terms of use\r\n\r\nhttps://lumalabs.ai/dream-machine/api/terms\r\n\r\n## Privacy\r\n\r\nData from this model is sent from Replicate to Luma.\r\n\r\nhttps://lumalabs.ai/legal/privacy"
    },
    {
      "id": "photon-flash",
      "name": "photon-flash",
      "owner": "luma",
      "fullName": "luma/photon-flash",
      "createdAt": "2024-12-05T15:18:04.364421Z",
      "runCount": 184895,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/8459f7e9-7445-4046-82aa-917a0f561b80/tmpyf9dx02r.webp",
      "url": "https://replicate.com/luma/photon-flash",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "16:9",
          "isImageInput": true
        },
        "image_reference": {
          "type": "string",
          "description": "Reference image to guide generation",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "style_reference": {
          "type": "string",
          "description": "Style reference image to guide generation",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "character_reference": {
          "type": "string",
          "description": "Character reference image to guide generation",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "image_reference_url": {
          "type": "string",
          "description": "Deprecated: Use image_reference instead",
          "required": false,
          "isImageInput": true
        },
        "style_reference_url": {
          "type": "string",
          "description": "Deprecated: Use style_reference instead",
          "required": false
        },
        "image_reference_weight": {
          "type": "number",
          "description": "Weight of the reference image. Larger values will make the reference image have a stronger influence on the generated image.",
          "required": false,
          "default": 0.85,
          "isImageInput": true
        },
        "style_reference_weight": {
          "type": "number",
          "description": "Weight of the style reference image",
          "required": false,
          "default": 0.85,
          "isImageInput": true
        },
        "character_reference_url": {
          "type": "string",
          "description": "Deprecated: Use character_reference instead",
          "required": false
        }
      },
      "readme": "# Luma Photon\r\n\r\nA high-efficiency image generation model with enhanced creative capabilities and natural language understanding.\r\n\r\nhttps://lumalabs.ai/photon\r\n\r\n## Models\r\n\r\n- **Luma Photon**: Standard model optimized for quality\r\n- **Photon Flash**: High-speed variant optimized for efficiency\r\n\r\n## Key Capabilities\r\n\r\n- Advanced natural language understanding\r\n- Multi-turn iterative workflows\r\n- Character consistency from single reference images\r\n- Multi-image reference system\r\n- High prompt adherence\r\n\r\n## Technical Specifications\r\n\r\n### Performance Metrics\r\n\r\n- Outperforms existing models in blind evaluation tests\r\n- Specialized evaluation framework for creative use cases\r\n- Significantly improved efficiency compared to similar models\r\n\r\n### Architecture Features\r\n\r\n- Large context window for image generation\r\n- New architectural design optimized for efficiency\r\n- Enhanced reference image processing system\r\n\r\n## Terms of use\r\n\r\nhttps://lumalabs.ai/dream-machine/api/terms\r\n\r\n## Privacy\r\n\r\nData from this model is sent from Replicate to Luma.\r\n\r\nhttps://lumalabs.ai/legal/privacy"
    },
    {
      "id": "imagen-4-fast",
      "name": "imagen-4-fast",
      "owner": "google",
      "fullName": "google/imagen-4-fast",
      "createdAt": "2025-06-12T09:24:39.272587Z",
      "runCount": 1979576,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/73c5af65-f578-4113-b62c-2a56971cff2f/replicate-prediction-trmpwr78.webp",
      "url": "https://replicate.com/google/imagen-4-fast",
      "inputSchema": {
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output image",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        },
        "safety_filter_level": {
          "type": "string",
          "description": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked",
          "required": false,
          "default": "block_only_high"
        }
      },
      "readme": "## Googleâ€™s Imagen 4 Ultra\r\n\r\n- [Imagen 4](https://replicate.com/google/imagen-4)\r\n- [Imagen 4 Ultra](https://replicate.com/google/imagen-4-ultra)\r\n- [Imagen 4 Fast](https://replicate.com/google/imagen-4-fast)\r\n\r\nHigh-quality image generation model featuring:\r\n\r\n- **Fine detail rendering**: Superior clarity for intricate elements like fabrics, water droplets, and animal fur\r\n- **Style versatility**: Excels in both photorealistic and abstract styles\r\n- **Resolution flexibility**: Creates images in various aspect ratios up to 2K resolution\r\n- **Typography improvements**: Significantly enhanced text rendering capabilities for greeting cards, posters, and comics\r\n- **Fast variant**: Upcoming version promises up to 10x faster generation compared to Imagen 3"
    },
    {
      "id": "imagen-4-ultra",
      "name": "imagen-4-ultra",
      "owner": "google",
      "fullName": "google/imagen-4-ultra",
      "createdAt": "2025-05-21T16:33:09.432040Z",
      "runCount": 1079570,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/de4e6a23-fc3a-46cd-9001-23d395228ce7/replicate-prediction-2rhm6xx1.webp",
      "url": "https://replicate.com/google/imagen-4-ultra",
      "inputSchema": {
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output image",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        },
        "safety_filter_level": {
          "type": "string",
          "description": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked",
          "required": false,
          "default": "block_only_high"
        }
      },
      "readme": "## Googleâ€™s Imagen 4 Ultra\r\n\r\n- [Imagen 4](https://replicate.com/google/imagen-4)\r\n- [Imagen 4 Ultra](https://replicate.com/google/imagen-4-ultra)\r\n- [Imagen 4 Fast](https://replicate.com/google/imagen-4-fast)\r\n\r\nHigh-quality image generation model featuring:\r\n\r\n- **Fine detail rendering**: Superior clarity for intricate elements like fabrics, water droplets, and animal fur\r\n- **Style versatility**: Excels in both photorealistic and abstract styles\r\n- **Resolution flexibility**: Creates images in various aspect ratios up to 2K resolution\r\n- **Typography improvements**: Significantly enhanced text rendering capabilities for greeting cards, posters, and comics\r\n- **Fast variant**: Upcoming version promises up to 10x faster generation compared to Imagen 3"
    },
    {
      "id": "flux-fast",
      "name": "flux-fast",
      "owner": "prunaai",
      "fullName": "prunaai/flux-fast",
      "createdAt": "2025-05-20T10:54:56.008591Z",
      "runCount": 32667887,
      "isOfficial": true,
      "coverImageUrl": "https://replicate.delivery/xezq/Wwps3VwgYfxHVy03zOtDT8M3wzKoA2iDVGG35SvepGfVbXPrA/output_-1_0.jpeg",
      "url": "https://replicate.com/prunaai/flux-fast",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Seed",
          "required": false,
          "default": -1
        },
        "prompt": {
          "type": "string",
          "description": "Prompt",
          "required": true
        },
        "guidance": {
          "type": "number",
          "description": "Guidance scale",
          "required": false,
          "default": 3.5
        },
        "image_size": {
          "type": "integer",
          "description": "Base image size (longest side)",
          "required": false,
          "default": 1024,
          "isImageInput": true
        },
        "speed_mode": {
          "type": "string",
          "description": "Speed optimization level",
          "required": false,
          "default": "Extra Juiced ðŸ”¥ (more speed)"
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the output image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Output format",
          "required": false,
          "default": "jpg"
        },
        "output_quality": {
          "type": "integer",
          "description": "Output quality (for jpg and webp)",
          "required": false,
          "default": 80
        },
        "num_inference_steps": {
          "type": "integer",
          "description": "Number of inference steps",
          "required": false,
          "default": 28
        }
      },
      "readme": ""
    },
    {
      "id": "ideogram-v3-quality",
      "name": "ideogram-v3-quality",
      "owner": "ideogram-ai",
      "fullName": "ideogram-ai/ideogram-v3-quality",
      "createdAt": "2025-04-30T13:21:22.917252Z",
      "runCount": 1994751,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/f285d3d6-40bb-4f15-aa82-c163e33c6000/tmpx4azqibw.webp",
      "url": "https://replicate.com/ideogram-ai/ideogram-v3-quality",
      "inputSchema": {
        "mask": {
          "type": "string",
          "description": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "required": false,
          "format": "uri",
          "isImageInput": true,
          "isMask": true,
          "optionalForReferenceImages": true
        },
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "An image file to use for inpainting. You must also use a mask.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "resolution": {
          "type": "string",
          "description": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "style_type": {
          "type": "string",
          "description": "The styles help define the specific aesthetic of the image you want to generate.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "style_preset": {
          "type": "string",
          "description": "Apply a predefined artistic style to the generated image (V3 models only).",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "magic_prompt_option": {
          "type": "string",
          "description": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "required": false,
          "default": "Auto",
          "isImageInput": true
        },
        "style_reference_images": {
          "type": "array",
          "description": "A list of images to use as style references.",
          "required": false,
          "isImageInput": true
        }
      },
      "readme": "# Ideogram 3.0\r\n\r\n- [Turbo](https://replicate.com/ideogram-ai/ideogram-v3-turbo): fastest and cheapest at $0.03/image\r\n- [Balanced](https://replicate.com/ideogram-ai/ideogram-v3-balanced): a good balance between speed and quality at $0.06/image\r\n- [Quality](https://replicate.com/ideogram-ai/ideogram-v3-quality): slowest but highest quality at $0.09/image\r\n\r\n## Overview\r\n\r\nIdeogram 3.0 is a text-to-image model available on ideogram.ai and iOS. The model features improved image-prompt alignment, photorealism, and text rendering capabilities.\r\n\r\n## Key Features\r\n\r\n### Style References\r\n\r\n- Upload up to 3 reference images to control generation aesthetics\r\n- Random style feature provides access to 4.3 billion style presets\r\n- Reuse styles via Style Codes\r\n\r\n### Text and Layout Generation\r\n\r\n- Precise text generation for graphic design applications\r\n- Support for complex and lengthy text compositions\r\n- Enhanced typesetting capabilities\r\n\r\n### Visual Quality\r\n\r\n- Sophisticated spatial compositions\r\n- Precise lighting and color control\r\n- Detailed environmental elements\r\n- Realistic rendering\r\n\r\n## Use Cases\r\n\r\n- Graphic design\r\n- Advertising\r\n- Marketing\r\n- Small business branding\r\n- Logo creation\r\n- Promotional materials\r\n- Product photography"
    },
    {
      "id": "ideogram-v3-turbo",
      "name": "ideogram-v3-turbo",
      "owner": "ideogram-ai",
      "fullName": "ideogram-ai/ideogram-v3-turbo",
      "createdAt": "2025-04-30T13:21:08.936269Z",
      "runCount": 4223747,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/b55e9f9e-5f43-4cf8-99c8-c33cc8486f23/tmp0s1h52uw-1.webp",
      "url": "https://replicate.com/ideogram-ai/ideogram-v3-turbo",
      "inputSchema": {
        "mask": {
          "type": "string",
          "description": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "required": false,
          "format": "uri",
          "isImageInput": true,
          "isMask": true,
          "optionalForReferenceImages": true
        },
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "An image file to use for inpainting. You must also use a mask.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "resolution": {
          "type": "string",
          "description": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "style_type": {
          "type": "string",
          "description": "The styles help define the specific aesthetic of the image you want to generate.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "style_preset": {
          "type": "string",
          "description": "Apply a predefined artistic style to the generated image (V3 models only).",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "magic_prompt_option": {
          "type": "string",
          "description": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "required": false,
          "default": "Auto",
          "isImageInput": true
        },
        "style_reference_images": {
          "type": "array",
          "description": "A list of images to use as style references.",
          "required": false,
          "isImageInput": true
        }
      },
      "readme": "# Ideogram 3.0\r\n\r\n- [Turbo](https://replicate.com/ideogram-ai/ideogram-v3-turbo): fastest and cheapest at $0.03/image\r\n- [Balanced](https://replicate.com/ideogram-ai/ideogram-v3-balanced): a good balance between speed and quality at $0.06/image\r\n- [Quality](https://replicate.com/ideogram-ai/ideogram-v3-quality): slowest but highest quality at $0.09/image\r\n\r\n## Overview\r\n\r\nIdeogram 3.0 is a text-to-image model available on ideogram.ai and iOS. The model features improved image-prompt alignment, photorealism, and text rendering capabilities.\r\n\r\n## Key Features\r\n\r\n### Style References\r\n\r\n- Upload up to 3 reference images to control generation aesthetics\r\n- Random style feature provides access to 4.3 billion style presets\r\n- Reuse styles via Style Codes\r\n\r\n### Text and Layout Generation\r\n\r\n- Precise text generation for graphic design applications\r\n- Support for complex and lengthy text compositions\r\n- Enhanced typesetting capabilities\r\n\r\n### Visual Quality\r\n\r\n- Sophisticated spatial compositions\r\n- Precise lighting and color control\r\n- Detailed environmental elements\r\n- Realistic rendering\r\n\r\n## Use Cases\r\n\r\n- Graphic design\r\n- Advertising\r\n- Marketing\r\n- Small business branding\r\n- Logo creation\r\n- Promotional materials\r\n- Product photography"
    },
    {
      "id": "ideogram-v3-balanced",
      "name": "ideogram-v3-balanced",
      "owner": "ideogram-ai",
      "fullName": "ideogram-ai/ideogram-v3-balanced",
      "createdAt": "2025-04-30T13:20:54.764024Z",
      "runCount": 318504,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/efc494c7-8e1b-4127-9e95-9e5376f7eb78/tmphco6mpqu.webp",
      "url": "https://replicate.com/ideogram-ai/ideogram-v3-balanced",
      "inputSchema": {
        "mask": {
          "type": "string",
          "description": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "required": false,
          "format": "uri",
          "isImageInput": true,
          "isMask": true,
          "optionalForReferenceImages": true
        },
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "An image file to use for inpainting. You must also use a mask.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "resolution": {
          "type": "string",
          "description": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "style_type": {
          "type": "string",
          "description": "The styles help define the specific aesthetic of the image you want to generate.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "style_preset": {
          "type": "string",
          "description": "Apply a predefined artistic style to the generated image (V3 models only).",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "magic_prompt_option": {
          "type": "string",
          "description": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "required": false,
          "default": "Auto",
          "isImageInput": true
        },
        "style_reference_images": {
          "type": "array",
          "description": "A list of images to use as style references.",
          "required": false,
          "isImageInput": true
        }
      },
      "readme": "# Ideogram 3.0\r\n\r\n- [Turbo](https://replicate.com/ideogram-ai/ideogram-v3-turbo): fastest and cheapest at $0.03/image\r\n- [Balanced](https://replicate.com/ideogram-ai/ideogram-v3-balanced): a good balance between speed and quality at $0.06/image\r\n- [Quality](https://replicate.com/ideogram-ai/ideogram-v3-quality): slowest but highest quality at $0.09/image\r\n\r\n## Overview\r\n\r\nIdeogram 3.0 is a text-to-image model available on ideogram.ai and iOS. The model features improved image-prompt alignment, photorealism, and text rendering capabilities.\r\n\r\n## Key Features\r\n\r\n### Style References\r\n\r\n- Upload up to 3 reference images to control generation aesthetics\r\n- Random style feature provides access to 4.3 billion style presets\r\n- Reuse styles via Style Codes\r\n\r\n### Text and Layout Generation\r\n\r\n- Precise text generation for graphic design applications\r\n- Support for complex and lengthy text compositions\r\n- Enhanced typesetting capabilities\r\n\r\n### Visual Quality\r\n\r\n- Sophisticated spatial compositions\r\n- Precise lighting and color control\r\n- Detailed environmental elements\r\n- Realistic rendering\r\n\r\n## Use Cases\r\n\r\n- Graphic design\r\n- Advertising\r\n- Marketing\r\n- Small business branding\r\n- Logo creation\r\n- Promotional materials\r\n- Product photography"
    },
    {
      "id": "flux-dev-lora",
      "name": "flux-dev-lora",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-dev-lora",
      "createdAt": "2024-11-11T23:03:07.000926Z",
      "runCount": 5042763,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/a79cc4a8-318c-4316-a800-097ef0bdce7a/https___replicate.del_25H5GQ7.webp",
      "url": "https://replicate.com/black-forest-labs/flux-dev-lora",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "Input image for image to image mode. The aspect ratio of your output will match this image",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Prompt for generated image",
          "required": true,
          "isImageInput": true
        },
        "go_fast": {
          "type": "boolean",
          "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed.",
          "required": false,
          "default": true
        },
        "guidance": {
          "type": "number",
          "description": "Guidance for generated image",
          "required": false,
          "default": 3,
          "isImageInput": true
        },
        "extra_lora": {
          "type": "string",
          "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>, CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet. For example, 'fofr/flux-pixar-cars'",
          "required": false
        },
        "lora_scale": {
          "type": "number",
          "description": "Determines how strongly the main LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "required": false,
          "default": 1
        },
        "megapixels": {
          "type": "string",
          "description": "Approximate number of megapixels for generated image",
          "required": false,
          "default": "1",
          "isImageInput": true
        },
        "num_outputs": {
          "type": "integer",
          "description": "Number of outputs to generate",
          "required": false,
          "default": 1
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "hf_api_token": {
          "type": "string",
          "description": "HuggingFace API token. If you're using a hf lora that needs authentication, you'll need to provide an API token.",
          "required": false,
          "format": "password"
        },
        "lora_weights": {
          "type": "string",
          "description": "Load LoRA weights. Supports Replicate models in the format <owner>/<username> or <owner>/<username>/<version>, HuggingFace URLs in the format huggingface.co/<owner>/<model-name>[/<lora-weights-file.safetensors>], CivitAI URLs in the format civitai.com/models/<id>[/<model-name>], or arbitrary .safetensors URLs from the Internet, including signed URLs. For example, 'fofr/flux-pixar-cars'. Civit AI and HuggingFace LoRAs may require an API token to access, which you can provide in the `civitai_api_token` and `hf_api_token` inputs respectively.",
          "required": false
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 80,
          "isImageInput": true
        },
        "prompt_strength": {
          "type": "number",
          "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "required": false,
          "default": 0.8,
          "isImageInput": true
        },
        "extra_lora_scale": {
          "type": "number",
          "description": "Determines how strongly the extra LoRA should be applied. Sane results between 0 and 1 for base inference. For go_fast we apply a 1.5x multiplier to this value; we've generally seen good performance when scaling the base value by that amount. You may still need to experiment to find the best value for your particular lora.",
          "required": false,
          "default": 1
        },
        "civitai_api_token": {
          "type": "string",
          "description": "Civitai API token. If you're using a civitai lora that needs authentication, you'll need to provide an API token.",
          "required": false,
          "format": "password"
        },
        "num_inference_steps": {
          "type": "integer",
          "description": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "required": false,
          "default": 28
        },
        "disable_safety_checker": {
          "type": "boolean",
          "description": "Disable safety checker for generated images.",
          "required": false,
          "default": false,
          "isImageInput": true
        }
      },
      "readme": "![](https://tjzk.replicate.delivery/markdownx/44d3556c-2848-45d3-8bbb-8be67da8ba3e.jpg)\r\n\r\n`FLUX.1 [dev]` is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.\r\nFor more information, please read our [blog post](https://blackforestlabs.ai/announcing-black-forest-labs/).\r\n\r\n# Key Features\r\n1. Cutting-edge output quality, second only to our state-of-the-art model `FLUX.1 [pro]`.\r\n2. Competitive prompt following, matching the performance of closed source alternatives .\r\n3. Trained using guidance distillation, making `FLUX.1 [dev]` more efficient.\r\n4. Open weights to drive new scientific research, and empower artists to develop innovative workflows.\r\n5. Generated outputs can be used for personal, scientific, and commercial purposes as described in the [flux-1-dev-non-commercial-license](https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md).\r\n\r\n# Usage\r\nWe provide a reference implementation of `FLUX.1 [dev]`, as well as sampling code, in a dedicated [github repository](https://github.com/black-forest-labs/flux).\r\nDevelopers and creatives looking to build on top of `FLUX.1 [dev]` are encouraged to use this as a starting point.\r\n\r\n## CivitAI:\r\nLocate the right LoRA for FLUX. Right click and \"Copy Link Address\" and paste into the `lora_weights` parameter:\r\n![civitai](https://cdn.discordapp.com/attachments/1334708715810717759/1406668268302893106/Screenshot_2025-08-17_at_11.55.12_AM.png?ex=68a34d69&is=68a1fbe9&hm=e44e9fa099e8151fe9346b3870cd7ce15f74342a04c43e5bdd6255746d4a4b2d&)\r\n\r\n## ComfyUI\r\n`FLUX.1 [dev]` is also available in [Comfy UI](https://github.com/comfyanonymous/ComfyUI) for local inference with a node-based workflow.\r\n\r\n# Limitations\r\n- This model is not intended or able to provide factual information.\r\n- As a statistical model this checkpoint might amplify existing societal biases.\r\n- The model may fail to generate output that matches the prompts.\r\n- Prompt following is heavily influenced by the prompting-style.\r\n\r\n# Out-of-Scope Use\r\nThe model and its derivatives may not be used\r\n\r\n- In any way that violates any applicable national, federal, state, local or international law or regulation.\r\n- For the purpose of exploiting, harming or attempting to exploit or harm minors in any way; including but not limited to the solicitation, creation, acquisition, or dissemination of child exploitative content.\r\n- To generate or disseminate verifiably false information and/or content with the purpose of harming others.\r\n- To generate or disseminate personal identifiable information that can be used to harm an individual.\r\n- To harass, abuse, threaten, stalk, or bully individuals or groups of individuals.\r\n- To create non-consensual nudity or illegal pornographic content.\r\n- For fully automated decision making that adversely impacts an individual's legal rights or otherwise creates or modifies a binding, enforceable obligation.\r\n- Generating or facilitating large-scale disinformation campaigns.\r\n\r\n# Accelerated Inference\r\nWe provide a `go_fast` flag within the API which toggles a version of flux-schnell optimized for inference. Currently this version is a compiled fp8 quantization with an optimized attention kernel, which quantizes and fuses lora weights with base model weights at generation time. We'll update the model and this documentation as we develop further enhancements. \r\n\r\n# License\r\nIf you generate images on Replicate with FLUX.1 models and their fine-tunes, then you can use the images commercially.\r\n\r\nIf you download the weights off Replicate and generate images on your own computer, you can't use the images commercially."
    },
    {
      "id": "image-3.2",
      "name": "image-3.2",
      "owner": "bria",
      "fullName": "bria/image-3.2",
      "createdAt": "2025-07-01T15:28:36.210909Z",
      "runCount": 79265,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_cover_image/2b7f59a2-a4e2-4339-a873-756b93bdfa11/take_2.jpg",
      "url": "https://replicate.com/bria/image-3.2",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for expansion.",
          "required": false,
          "default": "1:1"
        },
        "enhance_image": {
          "type": "boolean",
          "description": "Enhance image details and clarity",
          "required": false,
          "default": false,
          "isImageInput": true
        },
        "guidance_scale": {
          "type": "number",
          "description": "Guidance scale (1-10)",
          "required": false
        },
        "negative_prompt": {
          "type": "string",
          "description": "Negative prompt for image generation",
          "required": false,
          "isImageInput": true
        },
        "prompt_enhancement": {
          "type": "boolean",
          "description": "Enhance prompt for more creative output",
          "required": false,
          "default": false
        }
      },
      "readme": "![bria](https://huggingface.co/briaai/BRIA-3.2/media/main/32-photo.jpg)\r\nBria 3.2 is the next-generation commercial-ready text-to-image model. With just 4 billion parameters, it provides exceptional aesthetics and text rendering, evaluated to be on par to leading open-source models, and outperforming other licensed models.\r\nIn addition to being built entirely on licensed data, 3.2 provides several advantages for enterprise and commercial use:\r\n\r\n\t- Efficient Compute - the model is X3 smaller than the equivalent models in the market (4B parameters vs 12B parameters other open source models)\r\n\r\n\t- Fine-tuning Speedup: 2x faster fine-tuning on L40S and A100.\r\n\r\nFor access to source code and weights: https://huggingface.co/briaai/BRIA-3.2\r\n\r\n[BRIA 3.2 Benchmark](https://f4e04.share-eu1.hsforms.com/2nS45z_zIQu-3YKtbRbrKPQ?utm_campaign=125033698-3.2%20T2I%20Release&utm_medium=email&_hsenc=p2ANqtz-82gv__K8Yk2M_ru-W52l3ElptTaBzC5LjgcyJ890ZDdnnwFpX7Z8rwNTwKust10zWeF5-B4YfxrPHaputpOqgZd_gYPw&_hsmi=112237510&utm_content=112237510&utm_source=hs_automation)"
    },
    {
      "id": "imagen-4",
      "name": "imagen-4",
      "owner": "google",
      "fullName": "google/imagen-4",
      "createdAt": "2025-05-21T15:15:07.422259Z",
      "runCount": 5704290,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/895ffdc5-07d6-4b16-ac62-b27ba5b24468/4ccgkq0a6xrm80cpykfszajfaw.webp",
      "url": "https://replicate.com/google/imagen-4",
      "inputSchema": {
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output image",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        },
        "safety_filter_level": {
          "type": "string",
          "description": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked",
          "required": false,
          "default": "block_only_high"
        }
      },
      "readme": "## Googleâ€™s Imagen 4\r\n\r\n- [Imagen 4](https://replicate.com/google/imagen-4)\r\n- [Imagen 4 Ultra](https://replicate.com/google/imagen-4-ultra)\r\n- [Imagen 4 Fast](https://replicate.com/google/imagen-4-fast)\r\n\r\nHigh-quality image generation model featuring:\r\n\r\n- **Fine detail rendering**: Superior clarity for intricate elements like fabrics, water droplets, and animal fur\r\n- **Style versatility**: Excels in both photorealistic and abstract styles\r\n- **Resolution flexibility**: Creates images in various aspect ratios up to 2K resolution\r\n- **Typography improvements**: Significantly enhanced text rendering capabilities for greeting cards, posters, and comics\r\n- **Fast variant**: Upcoming version promises up to 10x faster generation compared to Imagen 3"
    },
    {
      "id": "flux-kontext-pro",
      "name": "flux-kontext-pro",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-kontext-pro",
      "createdAt": "2025-05-27T08:26:25.135215Z",
      "runCount": 34832492,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/e74eecd6-daf1-4050-9f04-36313bd6f007/two-people-cropped.webp",
      "url": "https://replicate.com/black-forest-labs/flux-kontext-pro",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "required": true,
          "isImageInput": true
        },
        "input_image": {
          "type": "string",
          "description": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "required": false,
          "default": "match_input_image",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Output format for the generated image",
          "required": false,
          "default": "png",
          "isImageInput": true
        },
        "safety_tolerance": {
          "type": "integer",
          "description": "Safety tolerance, 0 is most strict and 6 is most permissive. 2 is currently the maximum allowed when input images are used.",
          "required": false,
          "default": 2,
          "isImageInput": true
        },
        "prompt_upsampling": {
          "type": "boolean",
          "description": "Automatic prompt improvement",
          "required": false,
          "default": false
        }
      },
      "readme": "# FLUX.1 Kontext - Text-Based Image Editing\r\n\r\nFLUX.1 Kontext is a state-of-the-art image editing model from Black Forest Labs that allows you to edit images using text prompts. It's the best in class for text-guided image editing and offers superior results compared to other models like OpenAI's 4o/gpt-image-1.\r\n\r\n## Available Models\r\n\r\n- **[FLUX.1 Kontext [dev]](https://replicate.com/black-forest-labs/flux-kontext-dev)**: Open-weight version with non-commercial license (commercial use available through Replicate)\r\n- **[FLUX.1 Kontext [pro]](https://replicate.com/black-forest-labs/flux-kontext-pro)**: State-of-the-art performance with high-quality outputs, great prompt following, and consistent results\r\n- **[FLUX.1 Kontext [max]](https://replicate.com/black-forest-labs/flux-kontext-max)**: Premium model with maximum performance and improved typography generation\r\n\r\n## What You Can Do\r\n\r\nKontext excels at:\r\n\r\n- **Style Transfer**: Convert photos to different art styles (watercolor, oil painting, sketches)\r\n- **Object/Clothing Changes**: Modify hairstyles, add accessories, change colors\r\n- **Text Editing**: Replace text in signs, posters, and labels\r\n- **Background Swapping**: Change environments while preserving subjects\r\n- **Character Consistency**: Maintain identity across multiple edits\r\n\r\n## Prompting Best Practices\r\n\r\n### Be Specific\r\n\r\n- Use clear, detailed language with exact colors and descriptions\r\n- Avoid vague terms like \"make it better\"\r\n- Name subjects directly: \"the woman with short black hair\" vs. \"she\"\r\n\r\n### Preserve Intentionally\r\n\r\n- Specify what should stay the same: \"while keeping the same facial features\"\r\n- Use \"maintain the original composition\" to preserve layout\r\n- For background changes: \"Change the background to a beach while keeping the person in the exact same position\"\r\n\r\n### Text Editing Tips\r\n\r\n- Use quotation marks: \"replace 'old text' with 'new text'\"\r\n- Stick to readable fonts\r\n- Match text length when possible to preserve layout\r\n\r\n### Style Transfer\r\n\r\n- Be specific about artistic styles: \"impressionist painting\" not \"artistic\"\r\n- Reference known movements: \"Renaissance\" or \"1960s pop art\"\r\n- Describe key traits: \"visible brushstrokes, thick paint texture\"\r\n\r\n### Complex Edits\r\n\r\n- Break into smaller steps for better results\r\n- Start simple and iterate\r\n- Use descriptive action verbs instead of \"transform\" for more control\r\n\r\n## Commercial Use\r\n\r\nWhen using FLUX.1 Kontext on Replicate, you're free to use outputs commercially in apps, marketing, or any business use.\r\n\r\n## Example Applications\r\n\r\nCheck out these [specialized apps](https://replicate.com/flux-kontext-apps) built with Kontext:\r\n\r\n- [Portrait series](https://replicate.com/flux-kontext-apps/portrait-series): Generate portrait variations from a single image\r\n- [Change haircut](https://replicate.com/flux-kontext-apps/change-haircut): Modify hairstyles and colors\r\n- [Iconic locations](https://replicate.com/flux-kontext-apps/iconic-locations): Place subjects in famous landmarks\r\n- [Professional headshot](https://replicate.com/flux-kontext-apps/professional-headshot): Create professional portraits\r\n\r\n## Tips Summary\r\n\r\n- **Be specific** with colors, styles, and descriptions\r\n- **Start simple** and iterate on successful edits\r\n- **Preserve intentionally** by stating what to keep unchanged\r\n- **Use quotation marks** for exact text replacements\r\n- **Control composition** by specifying camera angles and framing\r\n- **Choose verbs carefully** - \"change\" vs \"transform\" gives different results"
    },
    {
      "id": "flux-kontext-max",
      "name": "flux-kontext-max",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-kontext-max",
      "createdAt": "2025-05-28T22:08:03.621735Z",
      "runCount": 8564841,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/debc1069-7e6b-48a7-a71b-489cc7cf1323/replicate-prediction-np382f6t.webp",
      "url": "https://replicate.com/black-forest-labs/flux-kontext-max",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Text description of what you want to generate, or the instruction on how to edit the given image.",
          "required": true,
          "isImageInput": true
        },
        "input_image": {
          "type": "string",
          "description": "Image to use as reference. Must be jpeg, png, gif, or webp.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image. Use 'match_input_image' to match the aspect ratio of the input image.",
          "required": false,
          "default": "match_input_image",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Output format for the generated image",
          "required": false,
          "default": "png",
          "isImageInput": true
        },
        "safety_tolerance": {
          "type": "integer",
          "description": "Safety tolerance, 0 is most strict and 6 is most permissive. 2 is currently the maximum allowed when input images are used.",
          "required": false,
          "default": 2,
          "isImageInput": true
        },
        "prompt_upsampling": {
          "type": "boolean",
          "description": "Automatic prompt improvement",
          "required": false,
          "default": false
        }
      },
      "readme": "# FLUX.1 Kontext - Text-Based Image Editing\r\n\r\nFLUX.1 Kontext is a state-of-the-art image editing model from Black Forest Labs that allows you to edit images using text prompts. It's the best in class for text-guided image editing and offers superior results compared to other models like OpenAI's 4o/gpt-image-1.\r\n\r\n## Available Models\r\n\r\n- **[FLUX.1 Kontext [dev]](https://replicate.com/black-forest-labs/flux-kontext-dev)**: Open-weight version with non-commercial license (commercial use available through Replicate)\r\n- **[FLUX.1 Kontext [pro]](https://replicate.com/black-forest-labs/flux-kontext-pro)**: State-of-the-art performance with high-quality outputs, great prompt following, and consistent results\r\n- **[FLUX.1 Kontext [max]](https://replicate.com/black-forest-labs/flux-kontext-max)**: Premium model with maximum performance and improved typography generation\r\n\r\n## What You Can Do\r\n\r\nKontext excels at:\r\n\r\n- **Style Transfer**: Convert photos to different art styles (watercolor, oil painting, sketches)\r\n- **Object/Clothing Changes**: Modify hairstyles, add accessories, change colors\r\n- **Text Editing**: Replace text in signs, posters, and labels\r\n- **Background Swapping**: Change environments while preserving subjects\r\n- **Character Consistency**: Maintain identity across multiple edits\r\n\r\n## Prompting Best Practices\r\n\r\n### Be Specific\r\n\r\n- Use clear, detailed language with exact colors and descriptions\r\n- Avoid vague terms like \"make it better\"\r\n- Name subjects directly: \"the woman with short black hair\" vs. \"she\"\r\n\r\n### Preserve Intentionally\r\n\r\n- Specify what should stay the same: \"while keeping the same facial features\"\r\n- Use \"maintain the original composition\" to preserve layout\r\n- For background changes: \"Change the background to a beach while keeping the person in the exact same position\"\r\n\r\n### Text Editing Tips\r\n\r\n- Use quotation marks: \"replace 'old text' with 'new text'\"\r\n- Stick to readable fonts\r\n- Match text length when possible to preserve layout\r\n\r\n### Style Transfer\r\n\r\n- Be specific about artistic styles: \"impressionist painting\" not \"artistic\"\r\n- Reference known movements: \"Renaissance\" or \"1960s pop art\"\r\n- Describe key traits: \"visible brushstrokes, thick paint texture\"\r\n\r\n### Complex Edits\r\n\r\n- Break into smaller steps for better results\r\n- Start simple and iterate\r\n- Use descriptive action verbs instead of \"transform\" for more control\r\n\r\n## Commercial Use\r\n\r\nWhen using FLUX.1 Kontext on Replicate, you're free to use outputs commercially in apps, marketing, or any business use.\r\n\r\n## Example Applications\r\n\r\nCheck out these [specialized apps](https://replicate.com/flux-kontext-apps) built with Kontext:\r\n\r\n- [Portrait series](https://replicate.com/flux-kontext-apps/portrait-series): Generate portrait variations from a single image\r\n- [Change haircut](https://replicate.com/flux-kontext-apps/change-haircut): Modify hairstyles and colors\r\n- [Iconic locations](https://replicate.com/flux-kontext-apps/iconic-locations): Place subjects in famous landmarks\r\n- [Professional headshot](https://replicate.com/flux-kontext-apps/professional-headshot): Create professional portraits\r\n\r\n## Tips Summary\r\n\r\n- **Be specific** with colors, styles, and descriptions\r\n- **Start simple** and iterate on successful edits\r\n- **Preserve intentionally** by stating what to keep unchanged\r\n- **Use quotation marks** for exact text replacements\r\n- **Control composition** by specifying camera angles and framing\r\n- **Choose verbs carefully** - \"change\" vs \"transform\" gives different results"
    },
    {
      "id": "wan-2.2-image",
      "name": "wan-2.2-image",
      "owner": "prunaai",
      "fullName": "prunaai/wan-2.2-image",
      "createdAt": "2025-07-16T14:52:23.200746Z",
      "runCount": 770122,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/4a0b1acf-473a-41d8-9e7c-e70ca5063ff7/replicate-prediction-37n3yfc9.jpeg",
      "url": "https://replicate.com/prunaai/wan-2.2-image",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "juiced": {
          "type": "boolean",
          "description": "Faster inference with additional optimizations.",
          "required": false,
          "default": false
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "megapixels": {
          "type": "string",
          "description": "Approximate number of megapixels for generated image",
          "required": false,
          "default": 2,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "16:9",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 80,
          "isImageInput": true
        }
      },
      "readme": ""
    },
    {
      "id": "qwen-image",
      "name": "qwen-image",
      "owner": "qwen",
      "fullName": "qwen/qwen-image",
      "createdAt": "2025-08-04T17:23:39.724770Z",
      "runCount": 965642,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/62e062a1-f4e4-4192-9f0c-56408f092fec/replicate-prediction-97qabd8z.webp",
      "url": "https://replicate.com/qwen/qwen-image",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "Input image for img2img pipeline",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Prompt for generated image",
          "required": true,
          "isImageInput": true
        },
        "go_fast": {
          "type": "boolean",
          "description": "Run faster predictions with additional optimizations.",
          "required": false,
          "default": true
        },
        "guidance": {
          "type": "number",
          "description": "Guidance for generated image. Lower values can give more realistic images. Good values to try are 2, 2.5, 3 and 3.5",
          "required": false,
          "default": 3,
          "isImageInput": true
        },
        "strength": {
          "type": "number",
          "description": "Strength for img2img pipeline",
          "required": false,
          "default": 0.9
        },
        "image_size": {
          "type": "string",
          "description": "Image size for the generated image",
          "required": false,
          "default": "optimize_for_quality",
          "isImageInput": true
        },
        "lora_scale": {
          "type": "number",
          "description": "Determines how strongly the main LoRA should be applied.",
          "required": false,
          "default": 1
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "16:9",
          "isImageInput": true
        },
        "lora_weights": {
          "type": "string",
          "description": "Load LoRA weights. Only works with text to image pipeline. Supports arbitrary .safetensors URLs, tar files, and zip files from the Internet (for example, 'https://huggingface.co/Viktor1717/scandinavian-interior-style1/resolve/main/my_first_flux_lora_v1.safetensors', 'https://example.com/lora_weights.tar.gz', or 'https://example.com/lora_weights.zip')",
          "required": false,
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "enhance_prompt": {
          "type": "boolean",
          "description": "Enhance the prompt with positive magic.",
          "required": false,
          "default": false
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 80,
          "isImageInput": true
        },
        "negative_prompt": {
          "type": "string",
          "description": "Negative prompt for generated image",
          "required": false,
          "default": " ",
          "isImageInput": true
        },
        "replicate_weights": {
          "type": "string",
          "description": "Load LoRA weights from Replicate training. Only works with text to image pipeline. Supports arbitrary .safetensors URLs, tar files, and zip files from the Internet.",
          "required": false,
          "isImageInput": true
        },
        "num_inference_steps": {
          "type": "integer",
          "description": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "required": false,
          "default": 30
        },
        "disable_safety_checker": {
          "type": "boolean",
          "description": "Disable safety checker for generated images.",
          "required": false,
          "default": false,
          "isImageInput": true
        }
      },
      "readme": "## Introduction\r\n\r\nWe are thrilled to release **Qwen-Image**, an image generation foundation model in the Qwen series that achieves significant advances in **complex text rendering** and **precise image editing**. Experiments show strong general capabilities in both image generation and editing, with exceptional performance in text rendering, especially for Chinese.\r\n\r\n![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/bench.png#center)\r\n\r\n## News\r\n- 2025.08.04: We released the [Technical Report](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/Qwen_Image.pdf) of Qwen-Image!\r\n- 2025.08.04: We released Qwen-Image weights! Check at [huggingface](https://huggingface.co/Qwen/Qwen-Image) and [Modelscope](https://modelscope.cn/models/Qwen/Qwen-Image)!\r\n- 2025.08.04: We released Qwen-Image! Check our [blog](https://qwenlm.github.io/blog/qwen-image) for more details!\r\n\r\n\r\n## Showcase\r\n\r\nOne of its standout capabilities is high-fidelity text rendering across diverse images. Whether itâ€™s alphabetic languages like English or logographic scripts like Chinese, Qwen-Image preserves typographic details, layout coherence, and contextual harmony with stunning accuracy. Text isnâ€™t just overlaidâ€”itâ€™s seamlessly integrated into the visual fabric.\r\n\r\n![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/s1.jpg#center)\r\n\r\nBeyond text, Qwen-Image excels at general image generation with support for a wide range of artistic styles. From photorealistic scenes to impressionist paintings, from anime aesthetics to minimalist design, the model adapts fluidly to creative prompts, making it a versatile tool for artists, designers, and storytellers.\r\n\r\n![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/s2.jpg#center)\r\n\r\nWhen it comes to image editing, Qwen-Image goes far beyond simple adjustments. It enables advanced operations such as style transfer, object insertion or removal, detail enhancement, text editing within images, and even human pose manipulationâ€”all with intuitive input and coherent output. This level of control brings professional-grade editing within reach of everyday users.\r\n\r\n![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/s3.jpg#center)\r\n\r\nBut Qwen-Image doesnâ€™t just create or editâ€”it understands. It supports a suite of image understanding tasks, including object detection, semantic segmentation, depth and edge (Canny) estimation, novel view synthesis, and super-resolution. These capabilities, while technically distinct, can all be seen as specialized forms of intelligent image editing, powered by deep visual comprehension.\r\n\r\n![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/s4.jpg#center)\r\n\r\nTogether, these features make Qwen-Image not just a tool for generating pretty pictures, but a comprehensive foundation model for intelligent visual creation and manipulationâ€”where language, layout, and imagery converge.\r\n\r\n\r\n## License Agreement\r\n\r\nQwen-Image is licensed under Apache 2.0. \r\n\r\n## Citation\r\n\r\nWe kindly encourage citation of our work if you find it useful.\r\n\r\n```bibtex\r\n@article{qwen-image,\r\n    title={Qwen-Image Technical Report}, \r\n    author={Qwen Team},\r\n    journal={arXiv preprint},\r\n    year={2025}\r\n}\r\n```"
    },
    {
      "id": "seedream-4",
      "name": "seedream-4",
      "owner": "bytedance",
      "fullName": "bytedance/seedream-4",
      "createdAt": "2025-09-09T11:23:42.672377Z",
      "runCount": 11655151,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/53dda182-2998-4fde-b235-e1b2a09b0484/seedream4-sm.jpg",
      "url": "https://replicate.com/bytedance/seedream-4",
      "inputSchema": {
        "size": {
          "type": "string",
          "description": "Image resolution: 1K (1024px), 2K (2048px), 4K (4096px), or 'custom' for specific dimensions.",
          "required": false,
          "default": "2K",
          "isImageInput": true
        },
        "width": {
          "type": "integer",
          "description": "Custom image width (only used when size='custom'). Range: 1024-4096 pixels.",
          "required": false,
          "default": 2048,
          "isImageInput": true
        },
        "height": {
          "type": "integer",
          "description": "Custom image height (only used when size='custom'). Range: 1024-4096 pixels.",
          "required": false,
          "default": 2048,
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "max_images": {
          "type": "integer",
          "description": "Maximum number of images to generate when sequential_image_generation='auto'. Range: 1-15. Total images (input + generated) cannot exceed 15.",
          "required": false,
          "default": 1,
          "isImageInput": true
        },
        "image_input": {
          "type": "array",
          "description": "Input image(s) for image-to-image generation. List of 1-10 images for single or multi-reference generation.",
          "required": false,
          "default": [],
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Image aspect ratio. Only used when size is not 'custom'. Use 'match_input_image' to automatically match the input image's aspect ratio.",
          "required": false,
          "default": "match_input_image",
          "isImageInput": true
        },
        "enhance_prompt": {
          "type": "boolean",
          "description": "Enable prompt enhancement for higher quality results, this will take longer to generate.",
          "required": false,
          "default": true
        },
        "sequential_image_generation": {
          "type": "string",
          "description": "Group image generation mode. 'disabled' generates a single image. 'auto' lets the model decide whether to generate multiple related images (e.g., story scenes, character variations).",
          "required": false,
          "default": "disabled",
          "isImageInput": true
        }
      },
      "readme": "# Seedream 4.0\r\n\r\nSeedream 4.0 is ByteDanceâ€™s next-generation image creation model that combines text-to-image generation and image editing into a single architecture. It offers fast, high-resolution image generation, rich prompt understanding, and support for multi-reference and batch workflows.\r\n\r\n## Key Features\r\n\r\n- **Unified generation & editing**  \r\n  Both text-to-image creation and image modifications (e.g. removing or replacing objects) are handled in one modelâ€”no need for separate tools.\r\n\r\n- **High-resolution and fast inference**  \r\n  Produces outputs up to 4K with significantly faster inference than prior versions.\r\n\r\n- **Batch and multi-reference support**  \r\n  Accepts multiple reference images and returns multiple outputs in one request.\r\n\r\n- **Natural-language prompt editing**  \r\n  Make precise edits using simple language, like â€œRemove the boy in this pictureâ€ or â€œReplace this dog with a Schnauzer.â€\r\n\r\n- **Versatile style transfer**  \r\n  Apply diverse visual styles such as watercolor, cyberpunk, or architectural to inputs or prompts.\r\n\r\n- **Knowledge-driven generation**  \r\n  Capable of complex content like educational illustrations, charts, timelines, or annotated scenes, with strong reasoning and prompt-following abilities.\r\n\r\n## Use Cases\r\n\r\n| Scenario                        | Example                                                                 |\r\n|---------------------------------|-------------------------------------------------------------------------|\r\n| Creative agencies / designers   | Generate batches of concept art or storyboards from multi-image inputs. |\r\n| Illustration & education        | Produce accurate diagrams or timelines with labeled details.             |\r\n| Visual editing & prototyping    | Modify photos or designs via text prompts for fast iteration.            |\r\n\r\n---\r\n\r\n**Try the model yourself on the [Replicate Playground](https://replicate.com/google/nano-banana)** to explore its capabilities and see how it can enhance your creative workflow."
    },
    {
      "id": "nano-banana",
      "name": "nano-banana",
      "owner": "google",
      "fullName": "google/nano-banana",
      "createdAt": "2025-08-26T21:08:24.983047Z",
      "runCount": 38374688,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/ed879e99-71b5-4689-bed3-e7305e35a28a/this.png",
      "url": "https://replicate.com/google/nano-banana",
      "inputSchema": {
        "prompt": {
          "type": "string",
          "description": "A text description of the image you want to generate",
          "required": true,
          "isImageInput": true
        },
        "image_input": {
          "type": "array",
          "description": "Input images to transform or use as reference (supports multiple images)",
          "required": false,
          "default": [],
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "match_input_image",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output image",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        }
      },
      "readme": "# Nano Banana\r\n\r\nGoogle's state-of-the-art image generation and editing model designed for fast, conversational, and multi-turn creative workflows.\r\n\r\n## Overview\r\n\r\nGemini 2.5 Flash Image (internally codenamed \"nano-banana\") is a multimodal model that natively understands and generates images. This model combines high-quality image generation with powerful editing capabilities, all controlled through natural language prompts. It's designed for creators who need precise control over their visual content while maintaining efficiency and ease of use.\r\n\r\n## Key Features\r\n\r\n### Character and Style Consistency\r\nMaintain the same character, object, or style across multiple prompts and images. Place a character in different environments, showcase products from multiple angles, or generate consistent brand assets without time-consuming fine-tuning.\r\n\r\n### Multi-Image Fusion\r\nSeamlessly blend multiple input images into a single, cohesive visual. Integrate products into new scenes, restyle environments by combining different elements, or merge reference images to create unified compositions.\r\n\r\n### Conversational Editing\r\nMake precise, targeted edits using natural language descriptions. Blur backgrounds, remove objects, alter poses, add color to black-and-white photos, or make any other transformation by simply describing what you want.\r\n\r\n### Visual Reasoning\r\nLeverage Gemini's deep world knowledge for complex tasks that require genuine understanding. The model can interpret hand-drawn diagrams, follow multi-step instructions, and generate images that adhere to real-world logic and context.\r\n\r\n### Native Image Understanding\r\nThe model natively understands and generates images as part of its core architecture, enabling seamless workflows for both creation and editing without switching between different tools or models.\r\n\r\n## What Makes It Special\r\n\r\nGemini 2.5 Flash Image stands out for its ability to understand context and maintain visual coherence across edits. Unlike traditional image generation models that excel only at aesthetics, this model benefits from Gemini's extensive world knowledge, allowing it to handle tasks like reading hand-drawn diagrams, understanding spatial relationships, and following complex creative directions.\r\n\r\nThe model is particularly effective at preserving subject identity across generations. Whether you're creating a series of marketing images featuring the same product or developing character-consistent artwork for storytelling, the model maintains recognizable features without requiring additional training or fine-tuning.\r\n\r\n## Intended Use\r\n\r\nThis model is designed for:\r\n\r\n- **Creative professionals** who need consistent visual assets across campaigns\r\n- **Product designers** visualizing items in different contexts and angles\r\n- **Marketers** creating cohesive brand materials with consistent styling\r\n- **Content creators** generating character-consistent imagery for storytelling\r\n- **Developers** building applications that require conversational image editing\r\n- **Educators** creating visual materials that require semantic understanding\r\n\r\n## Limitations\r\n\r\nWhile Gemini 2.5 Flash Image is highly capable, there are some areas where it may not always deliver perfect results:\r\n\r\n- Small faces and fine facial details may occasionally lack precision\r\n- Complex text rendering within images may sometimes have spelling inconsistencies  \r\n- Character consistency, while strong, may not be 100% reliable in all scenarios\r\n- Very intricate fine details may require multiple refinement iterations\r\n\r\nThe model is actively being improved to address these limitations.\r\n\r\n## How It Works\r\n\r\nThe model processes both text and image inputs through its multimodal architecture. When generating or editing images, it uses its understanding of the Gemini model family's world knowledge to interpret requests contextually. For editing tasks, it can analyze existing images and apply transformations based on natural language descriptions. For generation tasks, it can reference multiple input images to maintain consistency or blend elements together.\r\n\r\nAll images created or edited with this model include SynthID watermarking technology, which embeds an invisible digital watermark to help identify AI-generated or AI-edited content.\r\n\r\n## Performance\r\n\r\nGemini 2.5 Flash Image demonstrates state-of-the-art performance in image editing tasks, as validated by LMArena benchmarks where it tested under the codename \"nano-banana.\" The model generates images 2-3 times faster than comparable models while maintaining high quality, making it particularly well-suited for applications requiring quick iteration and real-time creative workflows.\r\n\r\n## Ethical Considerations\r\n\r\nGoogle applies extensive filtering and data labeling to minimize harmful content in training datasets and reduce the likelihood of harmful outputs. The model undergoes red teaming and safety evaluations including content safety, child safety, and representation assessments.\r\n\r\nThe built-in SynthID watermarking ensures transparency by allowing AI-generated and AI-edited images to be identified, promoting responsible use of AI-generated visual content.\r\n\r\n## Tips for Best Results\r\n\r\n- **Be specific with descriptions**: Detailed prompts yield more accurate results\r\n- **Use natural language**: Describe edits conversationally as you would to a human designer\r\n- **Iterate progressively**: Make changes step-by-step rather than requesting complex multi-part edits at once\r\n- **Reference visual templates**: When maintaining consistency, use the same reference images across generations\r\n- **Leverage multi-image fusion**: Combine up to three images to achieve complex compositions\r\n- **Experiment with aspect ratios**: The model supports multiple aspect ratios for different use cases\r\n\r\n## Additional Resources\r\n\r\nFor detailed API documentation and implementation guides, visit the [Gemini API documentation](https://ai.google.dev/gemini-api/docs).\r\n\r\n---\r\n\r\n**Try the model yourself on the [Replicate Playground](https://replicate.com/google/nano-banana)** to explore its capabilities and see how it can enhance your creative workflow."
    },
    {
      "id": "imagen-3",
      "name": "imagen-3",
      "owner": "google",
      "fullName": "google/imagen-3",
      "createdAt": "2025-02-05T12:56:07.610594Z",
      "runCount": 1784834,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/6e164365-9cab-422b-bf05-76d127abe3a2/replicate-prediction-_OX51bG7.webp",
      "url": "https://replicate.com/google/imagen-3",
      "inputSchema": {
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output image",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        },
        "safety_filter_level": {
          "type": "string",
          "description": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked",
          "required": false,
          "default": "block_only_high"
        }
      },
      "readme": "# Imagen 3\r\n\r\nImagen 3 is DeepMind's latest text-to-image generative model, focusing on high-quality image generation with improved detail, lighting, and reduced artifacts.\r\n\r\n## Core Capabilities\r\n\r\n- Enhanced prompt understanding for complex image generation tasks\r\n- Improved text rendering for applications like presentations and typography\r\n- Support for diverse artistic styles from photorealism to animation\r\n- Better handling of lighting, textures, and fine details\r\n- Natural language prompt processing without requiring complex prompt engineering\r\n\r\n## Technical Improvements\r\n\r\n### Image Quality\r\n\r\n- Enhanced color balance and vibrancy\r\n- Improved texture rendering\r\n- Better detail preservation in complex scenes\r\n- Reduced artifact generation\r\n- More accurate style reproduction across different artistic genres\r\n\r\n### Prompt Processing\r\n\r\n- Support for longer, more detailed prompts\r\n- Better understanding of camera angles and composition requirements\r\n- Improved handling of specific style requests\r\n- Enhanced text rendering capabilities\r\n\r\n## Benchmarks\r\n\r\nPerformance metrics based on human evaluation using GenAI-Bench:\r\n\r\n- Highest score for visual quality among compared models\r\n- High accuracy in prompt response adherence\r\n- Strong performance in overall preference benchmarks\r\n\r\nDetailed benchmark methodology and results are available in Appendix D of the technical report.\r\n\r\n## Security Features\r\n\r\n- Built-in content filtering system\r\n- Dataset filtering to minimize harmful content\r\n- SynthID watermarking integration for image identification\r\n- Extensive red teaming and evaluations for: Fairness, Bias, Content safety\r\n\r\n## Technical Documentation\r\n\r\nFor detailed technical specifications and methodology, refer to the full technical report.\r\n\r\n## Integration\r\n\r\nSynthID watermarking is integrated by default, embedding digital watermarks directly into image pixels while remaining visually imperceptible.\r\n\r\n## Development Team\r\n\r\nCore development involved collaboration across multiple technical disciplines including:\r\n\r\n- Machine learning research\r\n- Computer vision\r\n- Natural language processing\r\n- Security engineering\r\n- Dataset engineering\r\n\r\nFor a complete list of contributors and their roles, refer to the technical report.\r\n\r\n## Privacy\r\n\r\nData from this model is sent from Replicate to Google.\r\n\r\nCheck their Privacy Policy for details:\r\n\r\nhttps://policies.google.com/privacy"
    },
    {
      "id": "imagen-3-fast",
      "name": "imagen-3-fast",
      "owner": "google",
      "fullName": "google/imagen-3-fast",
      "createdAt": "2025-02-06T11:08:28.996578Z",
      "runCount": 494623,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/980d64f7-991a-4610-9e94-1a59d1482329/tmpuxt6kt2a.webp",
      "url": "https://replicate.com/google/imagen-3-fast",
      "inputSchema": {
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output image",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        },
        "safety_filter_level": {
          "type": "string",
          "description": "block_low_and_above is strictest, block_medium_and_above blocks some prompts, block_only_high is most permissive but some prompts will still be blocked",
          "required": false,
          "default": "block_only_high"
        }
      },
      "readme": "# Imagen 3\r\n\r\nImagen 3 is DeepMind's latest text-to-image generative model, focusing on high-quality image generation with improved detail, lighting, and reduced artifacts.\r\n\r\n## Core Capabilities\r\n\r\n- Enhanced prompt understanding for complex image generation tasks\r\n- Improved text rendering for applications like presentations and typography\r\n- Support for diverse artistic styles from photorealism to animation\r\n- Better handling of lighting, textures, and fine details\r\n- Natural language prompt processing without requiring complex prompt engineering\r\n\r\n## Technical Improvements\r\n\r\n### Image Quality\r\n\r\n- Enhanced color balance and vibrancy\r\n- Improved texture rendering\r\n- Better detail preservation in complex scenes\r\n- Reduced artifact generation\r\n- More accurate style reproduction across different artistic genres\r\n\r\n### Prompt Processing\r\n\r\n- Support for longer, more detailed prompts\r\n- Better understanding of camera angles and composition requirements\r\n- Improved handling of specific style requests\r\n- Enhanced text rendering capabilities\r\n\r\n## Benchmarks\r\n\r\nPerformance metrics based on human evaluation using GenAI-Bench:\r\n\r\n- Highest score for visual quality among compared models\r\n- High accuracy in prompt response adherence\r\n- Strong performance in overall preference benchmarks\r\n\r\nDetailed benchmark methodology and results are available in Appendix D of the technical report.\r\n\r\n## Security Features\r\n\r\n- Built-in content filtering system\r\n- Dataset filtering to minimize harmful content\r\n- SynthID watermarking integration for image identification\r\n- Extensive red teaming and evaluations for: Fairness, Bias, Content safety\r\n\r\n## Technical Documentation\r\n\r\nFor detailed technical specifications and methodology, refer to the full technical report.\r\n\r\n## Integration\r\n\r\nSynthID watermarking is integrated by default, embedding digital watermarks directly into image pixels while remaining visually imperceptible.\r\n\r\n## Development Team\r\n\r\nCore development involved collaboration across multiple technical disciplines including:\r\n\r\n- Machine learning research\r\n- Computer vision\r\n- Natural language processing\r\n- Security engineering\r\n- Dataset engineering\r\n\r\nFor a complete list of contributors and their roles, refer to the technical report.\r\n\r\n## Privacy\r\n\r\nData from this model is sent from Replicate to Google.\r\n\r\nCheck their Privacy Policy for details:\r\n\r\nhttps://policies.google.com/privacy"
    },
    {
      "id": "fibo",
      "name": "fibo",
      "owner": "bria",
      "fullName": "bria/fibo",
      "createdAt": "2025-10-20T13:48:09.766846Z",
      "runCount": 1389,
      "isOfficial": true,
      "coverImageUrl": "https://replicate.delivery/xezq/xzfIcbiiL0w6RiHsDIqtVdfDTGpkqZp5erL6SKFDRKYCErIrA/tmpipy5jdr4.png",
      "url": "https://replicate.com/bria/fibo",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "Image file",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for expansion.",
          "required": false,
          "default": "1:1"
        },
        "guidance_scale": {
          "type": "integer",
          "description": "Guidance scale (1-10)",
          "required": false
        },
        "negative_prompt": {
          "type": "string",
          "description": "Negative prompt for image generation",
          "required": false,
          "isImageInput": true
        },
        "structured_prompt": {
          "type": "string",
          "description": "Structured prompt (JSON string). Use a structured_prompt from a previous generation's response or the /v2/structured_prompt/generate endpoint for precise refinement.",
          "required": false,
          "default": ""
        }
      },
      "readme": "Try [FIBO Chat](http://fibo-chat.replicate-models.workers.dev) to see how Fibo can generate, inspire, and refine images!\r\n\r\n![](https://tjzk.replicate.delivery/markdownx/d18d502d-9734-45b0-a8aa-b5f589340c9b.png)\r\n<h2>ðŸŒ Why FIBO? </h2>\r\nText-to-image models have mastered imagination - but not control. FIBO changes that.\r\n\r\nFIBO is trained on structured JSON captions up to 1,000+ words and designed to understand and control different visual parameters such as lighting, composition, color, and camera settings, enabling precise and reproducible outputs.\r\n\r\nWith only 8 billion parameters, FIBO provides a new level of image quality, prompt adherence and proffessional control.\r\nEnterprises demand repeatability, governance, and transparency. FIBO delivers - open-source, rights-clear, and ready for production.\r\n\r\nðŸ”‘ Key Features\r\n<p> - LLM guided JSON-native prompting: structured schemas up to 1,000+ words (lighting, camera, composition, DoF)</p>\r\n<p> - Iterative controlled generation: generate images from short prompts or keep refining and get inspiration from detailed JSONs and input images</p>\r\n<p> - Disentangled control: tweak a single attribute (e.g., camera angle) without breaking the scene.</p>\r\n<p> - Enterprise-grade: 100% licensed data; governance, repeatability, and legal clarity.</p>\r\n<p> - Wins in both text alignment and aesthetics on PRISM-style evaluations.</p>\r\n![](https://tjzk.replicate.delivery/markdownx/bacac108-8170-4a65-8a55-a75af72610ba.png)\r\n<h2>ðŸ’¡ What can you do with FIBO? </h2>\r\n\r\n<h3>Generate</h3>\r\nStart with a quick idea. FIBOâ€™s language model expands your short prompt into a rich, structured JSON prompt, then generates the image. You get both the image and the expanded prompt.\r\n<h3>Refine</h3>\r\nContinue from a detailed structured prompt and add a small instruction - for example, â€œbacklit,â€ â€œ85 mm,â€ or â€œwarmer skin tones.â€ FIBO updates only the requested attributes, re-generates the image, and returns the refined prompt alongside it.\r\n<h3>Inspire</h3>\r\nProvide an image instead of text. FIBOâ€™s vision-language model extracts a detailed prompt describing it, combines that with your creative intent, and generates new, related images - ideal for exploring new directions without altering the original."
    },
    {
      "id": "hunyuan-image-3",
      "name": "hunyuan-image-3",
      "owner": "tencent",
      "fullName": "tencent/hunyuan-image-3",
      "createdAt": "2025-10-07T12:45:22.952680Z",
      "runCount": 23622,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/8bc99691-a2be-4019-babd-6d5aa0602121/replicate-prediction-typfea3m.webp",
      "url": "https://replicate.com/tencent/hunyuan-image-3",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "go_fast": {
          "type": "boolean",
          "description": "Run faster predictions with additional optimizations.",
          "required": false,
          "default": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 95,
          "isImageInput": true
        },
        "disable_safety_checker": {
          "type": "boolean",
          "description": "Disable safety checker for generated images.",
          "required": false,
          "default": false,
          "isImageInput": true
        }
      },
      "readme": "<img src=\"https://huggingface.co/tencent/HunyuanImage-3.0/resolve/main/assets/logo.png\" alt=\"HunyuanImage-3.0 Logo\" width=\"600\">\r\n\r\n# ðŸŽ¨ HunyuanImage-3.0: A Powerful Native Multimodal Model for Image Generation\r\n\r\n\r\n<img src=\"https://huggingface.co/tencent/HunyuanImage-3.0/resolve/main/assets/banner.png\" alt=\"HunyuanImage-3.0 Banner\" width=\"800\">\r\n\r\n\r\n  <a href=https://hunyuan.tencent.com/image target=\"_blank\"><img src=https://img.shields.io/badge/Official%20Site-333399.svg?logo=homepage height=22px></a>\r\n  <a href=https://huggingface.co/tencent/HunyuanImage-3.0 target=\"_blank\"><img src=https://img.shields.io/badge/%F0%9F%A4%97%20Models-d96902.svg height=22px></a>\r\n  <a href=https://github.com/Tencent-Hunyuan/HunyuanImage-3.0 target=\"_blank\"><img src= https://img.shields.io/badge/Page-bb8a2e.svg?logo=github height=22px></a>\r\n  <a href=https://arxiv.org/pdf/2509.23951 target=\"_blank\"><img src=https://img.shields.io/badge/Report-b5212f.svg?logo=arxiv height=22px></a>\r\n  <a href=https://x.com/TencentHunyuan target=\"_blank\"><img src=https://img.shields.io/badge/Hunyuan-black.svg?logo=x height=22px></a>\r\n  <a href=https://docs.qq.com/doc/DUVVadmhCdG9qRXBU target=\"_blank\"><img src=https://img.shields.io/badge/ðŸ“š-PromptHandBook-blue.svg?logo=book height=22px></a>\r\n\r\n\r\n## ðŸ§© Community Contributions\r\n\r\nIf you develop/use HunyuanImage-3.0 in your projects, welcome to let us know.\r\n\r\n\r\n## ðŸ—‚ï¸ Contents\r\n- [ðŸ”¥ðŸ”¥ðŸ”¥ News](#-news)\r\n- [ðŸ§© Community Contributions](#-community-contributions)\r\n- [ðŸ“‘ Open-source Plan](#-open-source-plan)\r\n- [ðŸ“– Introduction](#-introduction)\r\n- [âœ¨ Key Features](#-key-features)\r\n- [ðŸ› ï¸ Dependencies and Installation](#-dependencies-and-installation)\r\n  - [ðŸ’» System Requirements](#-system-requirements)\r\n  - [ðŸ“¦ Environment Setup](#-environment-setup)\r\n  - [ðŸ“¥ Install Dependencies](#-install-dependencies)\r\n  - [Performance Optimizations](#performance-optimizations)\r\n- [ðŸš€ Usage](#-usage)\r\n  - [ðŸ”¥ Quick Start with Transformers](#-quick-start-with-transformers)\r\n  - [ðŸ  Local Installation & Usage](#-local-installation--usage)\r\n  - [ðŸŽ¨ Interactive Gradio Demo](#-interactive-gradio-demo)\r\n- [ðŸ§± Models Cards](#-models-cards)\r\n- [ðŸ“ Prompt Guide](#-prompt-guide)\r\n  - [Manually Writing Prompts](#manually-writing-prompts)\r\n  - [System Prompt For Automatic Rewriting the Prompt](#system-prompt-for-automatic-rewriting-the-prompt)\r\n  - [Advanced Tips](#advanced-tips)\r\n  - [More Cases](#more-cases)\r\n- [ðŸ“Š Evaluation](#-evaluation)\r\n- [ðŸ“š Citation](#-citation)\r\n- [ðŸ™ Acknowledgements](#-acknowledgements)\r\n- [ðŸŒŸðŸš€  Github Star History](#-github-star-history)\r\n\r\n---\r\n\r\n## ðŸ“– Introduction\r\n\r\n**HunyuanImage-3.0** is a groundbreaking native multimodal model that unifies multimodal understanding and generation within an autoregressive framework. Our text-to-image module achieves performance **comparable to or surpassing** leading closed-source models.\r\n\r\n\r\n<img src=\"./assets/framework.png\" alt=\"HunyuanImage-3.0 Framework\" width=\"90%\">\r\n\r\n\r\n## âœ¨ Key Features\r\n\r\n* ðŸ§  **Unified Multimodal Architecture:** Moving beyond the prevalent DiT-based architectures, HunyuanImage-3.0 employs a unified autoregressive framework. This design enables a more direct and integrated modeling of text and image modalities, leading to surprisingly effective and contextually rich image generation.\r\n\r\n* ðŸ† **The Largest Image Generation MoE Model:** This is the largest open-source image generation Mixture of Experts (MoE) model to date. It features 64 experts and a total of 80 billion parameters, with 13 billion activated per token, significantly enhancing its capacity and performance.\r\n\r\n* ðŸŽ¨ **Superior Image Generation Performance:** Through rigorous dataset curation and advanced reinforcement learning post-training, we've achieved an optimal balance between semantic accuracy and visual excellence. The model demonstrates exceptional prompt adherence while delivering photorealistic imagery with stunning aesthetic quality and fine-grained details.\r\n\r\n* ðŸ’­ **Intelligent World-Knowledge Reasoning:** The unified multimodal architecture endows HunyuanImage-3.0 with powerful reasoning capabilities. It leverages its extensive world knowledge to intelligently interpret user intent, automatically elaborating on sparse prompts with contextually appropriate details to produce superior, more complete visual outputs.\r\n\r\n\r\n## ðŸ› ï¸ Dependencies and Installation\r\n\r\n### ðŸ’» System Requirements\r\n\r\n* ðŸ–¥ï¸ **Operating System:** Linux\r\n* ðŸŽ® **GPU:** NVIDIA GPU with CUDA support\r\n* ðŸ’¾ **Disk Space:** 170GB for model weights\r\n* ðŸ§  **GPU Memory:** â‰¥3Ã—80GB (4Ã—80GB recommended for better performance)\r\n\r\n### ðŸ“¦ Environment Setup\r\n\r\n* ðŸ **Python:** 3.12+ (recommended and tested)\r\n* ðŸ”¥ **PyTorch:** 2.7.1\r\n* âš¡ **CUDA:** 12.8\r\n\r\n\r\n## ðŸ§± Models Cards\r\n\r\n| Model                     | Params | Download | Recommended VRAM | Supported |\r\n|---------------------------| --- | --- | --- | --- |\r\n| HunyuanImage-3.0          | 80B total (13B active) | [HuggingFace](https://huggingface.co/tencent/HunyuanImage-3.0) | â‰¥ 3 Ã— 80 GB | âœ… Text-to-Image\r\n| HunyuanImage-3.0-Instruct | 80B total (13B active) | [HuggingFace](https://huggingface.co/tencent/HunyuanImage-3.0-Instruct) | â‰¥ 3 Ã— 80 GB | âœ… Text-to-Image<br>âœ… Prompt Self-Rewrite <br>âœ… CoT Think\r\n\r\n\r\n\r\nNotes:\r\n- Install performance extras (FlashAttention, FlashInfer) for faster inference.\r\n- Multiâ€‘GPU inference is recommended for the Base model.\r\n\r\n\r\n## ðŸ“ Prompt Guide\r\n\r\n### Manually Writing Prompts.\r\nThe Pretrain Checkpoint does not automatically rewrite or enhance input prompts, Instruct Checkpoint can rewrite or enhance input prompts with thinking . For optimal results currently, we recommend community partners consulting our official guide on how to write effective prompts.\r\n\r\nReference: [HunyuanImage 3.0 Prompt Handbook](\r\nhttps://docs.qq.com/doc/DUVVadmhCdG9qRXBU)\r\n\r\n\r\n### System Prompt For Automatic Rewriting the Prompt.\r\n\r\nWe've included two system prompts in the PE folder of this repository that leverage DeepSeek to automatically enhance user inputs:\r\n\r\n* **system_prompt_universal**: This system prompt converts photographic style, artistic prompts into a detailed one.\r\n* **system_prompt_text_rendering**: This system prompt converts UI/Poster/Text Rending prompts to a deailed on that suits the model.\r\n\r\nNote that these system prompts are in Chinese because Deepseek works better with Chinese system prompts. If you want to use it for English oriented model, you may translate it into English or refer to the comments in the PE file as a guide.\r\n\r\nWe also create a [Yuanqi workflow](https://yuanqi.tencent.com/agent/H69VgtJdj3Dz) to implement the universal one, you can directly try it.\r\n\r\n### Advanced Tips\r\n- **Content Priority**: Focus on describing the main subject and action first, followed by details about the environment and style. A more general description framework is: **Main subject and scene + Image quality and style + Composition and perspective + Lighting and atmosphere + Technical parameters**. Keywords can be added both before and after this structure.\r\n\r\n- **Image resolution**: Our model not only supports multiple resolutions but also offers both **automatic and specified resolution** options. In auto mode, the model automatically predicts the image resolution based on the input prompt. In specified mode (like traditional DiT), the model outputs an image resolution that strictly aligns with the user's chosen resolution.\r\n\r\n### More Cases\r\nOur model can follow complex instructions to generate highâ€‘quality, creative images.\r\n\r\n<img src=\"https://huggingface.co/tencent/HunyuanImage-3.0/resolve/main/assets/banner_all.jpg\" width=100% alt=\"HunyuanImage 3.0 Demo\">\r\n\r\nOur model can effectively process very long text inputs, enabling users to precisely control the finer details of generated images. Extended prompts allow for intricate elements to be accurately captured, making it ideal for complex projects requiring precision and creativity.\r\n\r\n<table>\r\n<thead>\r\n</thead>\r\n<tbody>\r\n<tr>\r\n<td>\r\n<img src=\"./assets/pg_imgs/image1.png\" width=100%><details>\r\n<summary>Show prompt</summary>\r\nA cinematic medium shot captures a single Asian woman seated on a chair within a dimly lit room, creating an intimate and theatrical atmosphere. The composition is focused on the subject, rendered with rich colors and intricate textures that evoke a nostalgic and moody feeling.\r\n\r\nThe primary subject is a young Asian woman with a thoughtful and expressive countenance, her gaze directed slightly away from the camera. She is seated in a relaxed yet elegant posture on an ornate, vintage armchair. The chair is upholstered in a deep red velvet, its fabric showing detailed, intricate textures and slight signs of wear. She wears a simple, elegant dress in a dark teal hue, the material catching the light in a way that reveals its fine-woven texture. Her skin has a soft, matte quality, and the light delicately models the contours of her face and arms.\r\n\r\nThe surrounding room is characterized by its vintage decor, which contributes to the historic and evocative mood. In the immediate background, partially blurred due to a shallow depth of field consistent with a f/2.8 aperture, the wall is covered with wallpaper featuring a subtle, damask pattern. The overall color palette is a carefully balanced interplay of deep teal and rich red hues, creating a visually compelling and cohesive environment. The entire scene is detailed, from the fibers of the upholstery to the subtle patterns on the wall.\r\n\r\nThe lighting is highly dramatic and artistic, defined by high contrast and pronounced shadow play. A single key light source, positioned off-camera, projects gobo lighting patterns onto the scene, casting intricate shapes of light and shadow across the woman and the back wall. These dramatic shadows create a strong sense of depth and a theatrical quality. While some shadows are deep and defined, others remain soft, gently wrapping around the subject and preventing the loss of detail in darker areas. The soft focus on the background enhances the intimate feeling, drawing all attention to the expressive subject. The overall image presents a cinematic, photorealistic photography style.\r\n</details>\r\n</td>\r\n<td><img src=\"./assets/pg_imgs/image2.png\" width=100%><details>\r\n<summary>Show prompt</summary>\r\nA cinematic, photorealistic medium shot captures a high-contrast urban street corner, defined by the sharp intersection of light and shadow. The primary subject is the exterior corner of a building, rendered in a low-saturation, realistic style.\r\n\r\nThe building wall, which occupies the majority of the frame, is painted a warm orange with a finely detailed, rough stucco texture. Horizontal white stripes run across its surface. The base of the building is constructed from large, rough-hewn stone blocks, showing visible particles and texture. On the left, illuminated side of the building, there is a single window with closed, dark-colored shutters. Adjacent to the window, a simple black pendant lamp hangs from a thin, taut rope, casting a distinct, sharp-edged shadow onto the sunlit orange wall. The composition is split diagonally, with the right side of the building enveloped in a deep brown shadow. At the bottom of the frame, a smooth concrete sidewalk is visible, upon which the dynamic silhouette of a person is captured mid-stride, walking from right to left.\r\n\r\nIn the shallow background, the faint, out-of-focus outlines of another building and the bare, skeletal branches of trees are softly visible, contributing to the quiet urban atmosphere and adding a sense of depth to the scene. These elements are rendered with minimal detail to keep the focus on the foreground architecture.\r\n\r\nThe scene is illuminated by strong, natural sunlight originating from the upper left, creating a dramatic chiaroscuro effect. This hard light source casts deep, well-defined shadows, producing a sharp contrast between the brightly lit warm orange surfaces and the deep brown shadow areas. The lighting highlights the fine details in the wall texture and stone particles, emphasizing the photorealistic quality. The overall presentation reflects a high-quality photorealistic photography style, infused with a cinematic film noir aesthetic.\r\n</details>\r\n</td>\r\n</tr>\r\n</tbody>\r\n</table>\r\n\r\n## ðŸ“Š Evaluation\r\n\r\n* ðŸ¤– **SSAE (Machine Evaluation)**   \r\nSSAE (Structured Semantic Alignment Evaluation) is an intelligent evaluation metric for image-text alignment based on advanced multimodal large language models (MLLMs). We extracted 3500 key points across 12 categories, then used multimodal large language models to automatically evaluate and score by comparing the generated images with these key points based on the visual content of the images. Mean Image Accuracy represents the image-wise average score across all key points, while Global Accuracy directly calculates the average score across all key points.\r\n\r\n<p align=\"center\">\r\n  <img src=\"./assets/ssae_side_by_side_comparison.png\" width=98% alt=\"Human Evaluation with Other Models\">\r\n</p>\r\n\r\n<p align=\"center\">\r\n  <img src=\"./assets/ssae_side_by_side_heatmap.png\" width=98% alt=\"Human Evaluation with Other Models\">\r\n</p>\r\n\r\n\r\n* ðŸ‘¥ **GSB (Human Evaluation)** \r\n\r\nWe adopted the GSB (Good/Same/Bad) evaluation method commonly used to assess the relative performance between two models from an overall image perception perspective. In total, we utilized 1,000 text prompts, generating an equal number of image samples for all compared models in a single run. For a fair comparison, we conducted inference only once for each prompt, avoiding any cherry-picking of results. When comparing with the baseline methods, we maintained the default settings for all selected models. The evaluation was performed by more than 100 professional evaluators. \r\n\r\n<p align=\"center\">\r\n  <img src=\"./assets/gsb.png\" width=98% alt=\"Human Evaluation with Other Models\">\r\n</p>\r\n\r\n\r\n## ðŸ“š Citation\r\n\r\nIf you find HunyuanImage-3.0 useful in your research, please cite our work:\r\n\r\n```bibtex\r\n@article{cao2025hunyuanimage,\r\n  title={HunyuanImage 3.0 Technical Report},\r\n  author={Cao, Siyu and Chen, Hangting and Chen, Peng and Cheng, Yiji and Cui, Yutao and Deng, Xinchi and Dong, Ying and Gong, Kipper and Gu, Tianpeng and Gu, Xiusen and others},\r\n  journal={arXiv preprint arXiv:2509.23951},\r\n  year={2025}\r\n}\r\n```\r\n\r\n## ðŸ™ Acknowledgements\r\n\r\nWe extend our heartfelt gratitude to the following open-source projects and communities for their invaluable contributions:\r\n\r\n* ðŸ¤— [Transformers](https://github.com/huggingface/transformers) - State-of-the-art NLP library\r\n* ðŸŽ¨ [Diffusers](https://github.com/huggingface/diffusers) - Diffusion models library  \r\n* ðŸŒ [HuggingFace](https://huggingface.co/) - AI model hub and community\r\n* âš¡ [FlashAttention](https://github.com/Dao-AILab/flash-attention) - Memory-efficient attention\r\n* ðŸš€ [FlashInfer](https://github.com/flashinfer-ai/flashinfer) - Optimized inference engine\r\n\r\n## ðŸŒŸðŸš€ Github Star History\r\n\r\n[![GitHub stars](https://img.shields.io/github/stars/Tencent-Hunyuan/HunyuanImage-3.0?style=social)](https://github.com/Tencent-Hunyuan/HunyuanImage-3.0)\r\n[![GitHub forks](https://img.shields.io/github/forks/Tencent-Hunyuan/HunyuanImage-3.0?style=social)](https://github.com/Tencent-Hunyuan/HunyuanImage-3.0)\r\n\r\n\r\n[![Star History Chart](https://api.star-history.com/svg?repos=Tencent-Hunyuan/HunyuanImage-3.0&type=Date)](https://www.star-history.com/#Tencent-Hunyuan/HunyuanImage-3.0&Date)"
    },
    {
      "id": "lucid-origin",
      "name": "lucid-origin",
      "owner": "leonardoai",
      "fullName": "leonardoai/lucid-origin",
      "createdAt": "2025-09-08T14:44:30.621933Z",
      "runCount": 132642,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/d50a29d9-e92c-4589-90eb-ae267d1c3700/GxqkjvOWQAA0ST7.jpg",
      "url": "https://replicate.com/leonardoai/lucid-origin",
      "inputSchema": {
        "style": {
          "type": "string",
          "description": "Style to use for the output image",
          "required": false,
          "default": "none",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for generation",
          "required": true
        },
        "contrast": {
          "type": "string",
          "description": "Contrast level",
          "required": false,
          "default": "medium"
        },
        "num_images": {
          "type": "integer",
          "description": "Number of images to generate",
          "required": false,
          "default": 1,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the output image",
          "required": false,
          "default": "16:9",
          "isImageInput": true
        },
        "prompt_enhance": {
          "type": "boolean",
          "description": "Whether to enhance the prompt",
          "required": false,
          "default": true
        },
        "generation_mode": {
          "type": "string",
          "description": "Generation mode",
          "required": false,
          "default": "standard"
        }
      },
      "readme": "# Lucid Origin\r\n\r\nLucid Origin is a generative image model developed by Leonardo AI.  \r\nIt is designed to produce high-quality visuals with improved prompt adherence, diversity, and definition.\r\n\r\n## Features\r\n\r\n- **High Definition**  \r\n  Outputs in Full HD for sharper detail.\r\n\r\n- **Vibrancy**  \r\n  Generates images with stronger color depth and visual clarity.\r\n\r\n- **Diversity**  \r\n  Broader range of characters, cultures, and visual perspectives.\r\n\r\n- **Style Adaptability**  \r\n  Supports a wide range of aesthetics, from photorealism to illustrative and hand-drawn looks.\r\n\r\n- **Text and Layout Rendering**  \r\n  Capable of producing clean text and structured design elements for graphic and branding use cases.\r\n\r\n- **Prompt Responsiveness**  \r\n  Aims for consistent alignment with input prompts.\r\n\r\n## Development Notes\r\n\r\nLucid Origin was trained using curated datasets with attention to artistic quality and representation.  \r\nThe model combines aesthetic curation with technical methods to balance multiple layers of visual generation.  \r\nIt was developed by researchers and practitioners with backgrounds in art, photography, and machine learning."
    },
    {
      "id": "flux-dev",
      "name": "flux-dev",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-dev",
      "createdAt": "2024-07-29T23:25:06.100855Z",
      "runCount": 31774044,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/cb4203e5-9ece-42e7-b326-98ff3fa35c3a/Replicate_Prediction_15.webp",
      "url": "https://replicate.com/black-forest-labs/flux-dev",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "Input image for image to image mode. The aspect ratio of your output will match this image",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Prompt for generated image",
          "required": true,
          "isImageInput": true
        },
        "go_fast": {
          "type": "boolean",
          "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed.",
          "required": false,
          "default": true
        },
        "guidance": {
          "type": "number",
          "description": "Guidance for generated image",
          "required": false,
          "default": 3,
          "isImageInput": true
        },
        "megapixels": {
          "type": "string",
          "description": "Approximate number of megapixels for generated image",
          "required": false,
          "default": "1",
          "isImageInput": true
        },
        "num_outputs": {
          "type": "integer",
          "description": "Number of outputs to generate",
          "required": false,
          "default": 1
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 80,
          "isImageInput": true
        },
        "prompt_strength": {
          "type": "number",
          "description": "Prompt strength when using img2img. 1.0 corresponds to full destruction of information in image",
          "required": false,
          "default": 0.8,
          "isImageInput": true
        },
        "num_inference_steps": {
          "type": "integer",
          "description": "Number of denoising steps. Recommended range is 28-50, and lower number of steps produce lower quality outputs, faster.",
          "required": false,
          "default": 28
        },
        "disable_safety_checker": {
          "type": "boolean",
          "description": "Disable safety checker for generated images.",
          "required": false,
          "default": false,
          "isImageInput": true
        }
      },
      "readme": "![](https://tjzk.replicate.delivery/markdownx/44d3556c-2848-45d3-8bbb-8be67da8ba3e.jpg)\r\n\r\n`FLUX.1 [dev]` is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.\r\nFor more information, please read our [blog post](https://blackforestlabs.ai/announcing-black-forest-labs/).\r\n\r\n# Key Features\r\n1. Cutting-edge output quality, second only to our state-of-the-art model `FLUX.1 [pro]`.\r\n2. Competitive prompt following, matching the performance of closed source alternatives .\r\n3. Trained using guidance distillation, making `FLUX.1 [dev]` more efficient.\r\n4. Open weights to drive new scientific research, and empower artists to develop innovative workflows.\r\n5. Generated outputs can be used for personal, scientific, and commercial purposes as described in the [flux-1-dev-non-commercial-license](https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md).\r\n\r\n# Usage\r\nWe provide a reference implementation of `FLUX.1 [dev]`, as well as sampling code, in a dedicated [github repository](https://github.com/black-forest-labs/flux).\r\nDevelopers and creatives looking to build on top of `FLUX.1 [dev]` are encouraged to use this as a starting point.\r\n\r\n## ComfyUI\r\n`FLUX.1 [dev]` is also available in [Comfy UI](https://github.com/comfyanonymous/ComfyUI) for local inference with a node-based workflow.\r\n\r\n# Limitations\r\n- This model is not intended or able to provide factual information.\r\n- As a statistical model this checkpoint might amplify existing societal biases.\r\n- The model may fail to generate output that matches the prompts.\r\n- Prompt following is heavily influenced by the prompting-style.\r\n\r\n# Out-of-Scope Use\r\nThe model and its derivatives may not be used\r\n\r\n- In any way that violates any applicable national, federal, state, local or international law or regulation.\r\n- For the purpose of exploiting, harming or attempting to exploit or harm minors in any way; including but not limited to the solicitation, creation, acquisition, or dissemination of child exploitative content.\r\n- To generate or disseminate verifiably false information and/or content with the purpose of harming others.\r\n- To generate or disseminate personal identifiable information that can be used to harm an individual.\r\n- To harass, abuse, threaten, stalk, or bully individuals or groups of individuals.\r\n- To create non-consensual nudity or illegal pornographic content.\r\n- For fully automated decision making that adversely impacts an individual's legal rights or otherwise creates or modifies a binding, enforceable obligation.\r\n- Generating or facilitating large-scale disinformation campaigns.\r\n\r\n# Accelerated Inference\r\nWe provide a `go_fast` flag within the API which toggles a version of flux-schnell optimized for inference. Currently this version is a compiled fp8 quantization with an optimized attention kernel. We'll update the model and this documentation as we develop further enhancements. \r\n\r\n# License\r\nIf you generate images on Replicate with FLUX.1 models and their fine-tunes, then you can use the images commercially.\r\n\r\nIf you download the weights off Replicate and generate images on your own computer, you can't use the images commercially."
    },
    {
      "id": "ideogram-v2-turbo",
      "name": "ideogram-v2-turbo",
      "owner": "ideogram-ai",
      "fullName": "ideogram-ai/ideogram-v2-turbo",
      "createdAt": "2024-10-22T09:29:41.547244Z",
      "runCount": 2742336,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/8b1df940-d741-4446-beb2-0d72c66abb91/replicate-prediction-f_iX48w8f.png",
      "url": "https://replicate.com/ideogram-ai/ideogram-v2-turbo",
      "inputSchema": {
        "mask": {
          "type": "string",
          "description": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "required": false,
          "format": "uri",
          "isImageInput": true,
          "isMask": true,
          "optionalForReferenceImages": true
        },
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "An image file to use for inpainting. You must also use a mask.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "resolution": {
          "type": "string",
          "description": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "style_type": {
          "type": "string",
          "description": "The styles help define the specific aesthetic of the image you want to generate.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "negative_prompt": {
          "type": "string",
          "description": "Things you do not want to see in the generated image.",
          "required": false,
          "isImageInput": true
        },
        "magic_prompt_option": {
          "type": "string",
          "description": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "required": false,
          "default": "Auto",
          "isImageInput": true
        }
      },
      "readme": "## Ideogram v2 Turbo\r\n\r\nTurbo generates images quickly and is best used for ideation when you want a quick look at the composition. Sometimes useful for achieving a sketchy look (~7 to ~12 sec)\r\n\r\n## More about Ideogram\r\n\r\nhttps://docs.ideogram.ai/\r\n\r\nIdeogram (pronounced \"eye-dee-oh-gram\") is a free-to-use AI tool that turns your ideas into stunning images, in a matter of seconds. Ideogram excels at creating captivating designs, realistic images, innovative logos and posters. With unique capabilities like text rendering in images, we aim to inspire creativity and help every user bring their imagination to life.\r\n\r\n## Features\r\n\r\nhttps://docs.ideogram.ai/using-ideogram/ideogram-features"
    },
    {
      "id": "ideogram-v2",
      "name": "ideogram-v2",
      "owner": "ideogram-ai",
      "fullName": "ideogram-ai/ideogram-v2",
      "createdAt": "2024-10-22T09:26:23.607119Z",
      "runCount": 2538423,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/71c982a3-27f0-42a6-ad6a-769f25097c08/replicate-prediction-s_VROPz1s.png",
      "url": "https://replicate.com/ideogram-ai/ideogram-v2",
      "inputSchema": {
        "mask": {
          "type": "string",
          "description": "A black and white image. Black pixels are inpainted, white pixels are preserved. The mask will be resized to match the image size.",
          "required": false,
          "format": "uri",
          "isImageInput": true,
          "isMask": true,
          "optionalForReferenceImages": true
        },
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "An image file to use for inpainting. You must also use a mask.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "resolution": {
          "type": "string",
          "description": "Resolution. Overrides aspect ratio. Ignored if an inpainting image is given.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "style_type": {
          "type": "string",
          "description": "The styles help define the specific aesthetic of the image you want to generate.",
          "required": false,
          "default": "None",
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio. Ignored if a resolution or inpainting image is given.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "negative_prompt": {
          "type": "string",
          "description": "Things you do not want to see in the generated image.",
          "required": false,
          "isImageInput": true
        },
        "magic_prompt_option": {
          "type": "string",
          "description": "Magic Prompt will interpret your prompt and optimize it to maximize variety and quality of the images generated. You can also use it to write prompts in different languages.",
          "required": false,
          "default": "Auto",
          "isImageInput": true
        }
      },
      "readme": "## More about Ideogram\r\n\r\nhttps://docs.ideogram.ai/\r\n\r\nIdeogram (pronounced \"eye-dee-oh-gram\") is a free-to-use AI tool that turns your ideas into stunning images, in a matter of seconds. Ideogram excels at creating captivating designs, realistic images, innovative logos and posters. With unique capabilities like text rendering in images, we aim to inspire creativity and help every user bring their imagination to life.\r\n\r\n## Features\r\n\r\nhttps://docs.ideogram.ai/using-ideogram/ideogram-features"
    },
    {
      "id": "flux-pro",
      "name": "flux-pro",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-pro",
      "createdAt": "2024-08-01T09:32:10.863297Z",
      "runCount": 13602019,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_cover_image/a36275e2-34d4-4b3d-83cd-f9aaf73c9386/https___replicate.delive_o40qpZl.webp",
      "url": "https://replicate.com/black-forest-labs/flux-pro",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "steps": {
          "type": "integer",
          "description": "Deprecated",
          "required": false,
          "default": 25
        },
        "width": {
          "type": "integer",
          "description": "Width of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "required": false,
          "isImageInput": true
        },
        "height": {
          "type": "integer",
          "description": "Height of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "required": false,
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "guidance": {
          "type": "number",
          "description": "Controls the balance between adherence to the text prompt and image quality/diversity. Higher values make the output more closely match the prompt but may reduce overall image quality. Lower values allow for more creative freedom but might produce results less relevant to the prompt.",
          "required": false,
          "default": 3,
          "isImageInput": true
        },
        "interval": {
          "type": "number",
          "description": "Deprecated",
          "required": false,
          "default": 2
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "image_prompt": {
          "type": "string",
          "description": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images.",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 80,
          "isImageInput": true
        },
        "safety_tolerance": {
          "type": "integer",
          "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "required": false,
          "default": 2
        },
        "prompt_upsampling": {
          "type": "boolean",
          "description": "Automatically modify the prompt for more creative generation",
          "required": false,
          "default": false
        }
      },
      "readme": "**FLUX.1 [pro]** is the best of FLUX.1, offering state-of-the-art performance image generation with top of the line prompt following, visual quality, image detail and output diversity. \r\n\r\nAll FLUX.1 model variants support a diverse range of aspect ratios and resolutions in 0.1 and 2.0 megapixels\r\n\r\nAll public FLUX.1 models are based on a hybrid architecture of [multimodal](https://arxiv.org/abs/2403.03206) and [parallel diffusion transformer](https://arxiv.org/abs/2302.05442) blocks and scaled to 12B parameters. We improve over previous state-of-the-art diffusion models by building on [flow matching](https://arxiv.org/abs/2210.02747), a general and conceptually simple method for training generative models, which includes diffusion as a special case. In addition, we increase model performance and improve hardware efficiency by incorporating [rotary positional embeddings](https://arxiv.org/abs/2104.09864) and [parallel attention layers](https://arxiv.org/abs/2302.05442).\r\n\r\n# License\r\n\r\nBy using FLUX.1 [pro] through Replicate you agree to the [Black Forest Labs API agreement](https://docs.bfl.ml/agreement/) and the [Black Forest Labs Terms of Service](https://blackforestlabs.ai/terms-of-service/)."
    },
    {
      "id": "stable-diffusion-3.5-large",
      "name": "stable-diffusion-3.5-large",
      "owner": "stability-ai",
      "fullName": "stability-ai/stable-diffusion-3.5-large",
      "createdAt": "2024-10-21T20:53:39.435334Z",
      "runCount": 1733474,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/4b03d178-eaf3-4458-a752-dbc76098396b/replicate-prediction-_ycGb1jN.webp",
      "url": "https://replicate.com/stability-ai/stable-diffusion-3.5-large",
      "inputSchema": {
        "cfg": {
          "type": "number",
          "description": "The guidance scale tells the model how similar the output should be to the prompt.",
          "required": false,
          "default": 5
        },
        "seed": {
          "type": "integer",
          "description": "Set a seed for reproducibility. Random by default.",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "Input image for image to image mode. The aspect ratio of your output will match this image.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "The aspect ratio of your output image. This value is ignored if you are using an input image.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "negative_prompt": {
          "type": "string",
          "description": "What you do not want to see in the image",
          "required": false,
          "isImageInput": true
        },
        "prompt_strength": {
          "type": "number",
          "description": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
          "required": false,
          "default": 0.85,
          "isImageInput": true
        }
      },
      "readme": "# Stable Diffusion 3.5 Large\r\n![3.5 Large Demo Image](https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/sd3.5_large_demo.png)\r\n\r\n## Model\r\n\r\n![MMDiT](https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/mmdit.png)\r\n\r\n\r\n[Stable Diffusion 3.5 Large](https://stability.ai/news/introducing-stable-diffusion-3-5) is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.\r\n\r\nPlease note: This model is released under the [Stability Community License](https://stability.ai/community-license-agreement). Visit [Stability AI](https://stability.ai/license) to learn or [contact us](https://stability.ai/enterprise) for commercial licensing details.\r\n\r\n\r\n### Model Description\r\n\r\n- **Developed by:** Stability AI\r\n- **Model type:** MMDiT text-to-image generative model\r\n- **Model Description:** This model generates images based on text prompts. It is a [Multimodal Diffusion Transformer](https://arxiv.org/abs/2403.03206) that use three fixed, pretrained text encoders, and with QK-normalization to improve training stability. \r\n\r\n\r\n## License\r\n\r\nThis model is available under the [Stability AI Community License](https://stability.ai/community-license-agreement):\r\n\r\n- **Non-commercial Use:** Free for non-commercial projects and research.\r\n- **Commercial Use:** Free if your company's annual revenue is less than $1 million.\r\n- **Ownership of Outputs:** You own the images you generate.\r\n\r\nPlease review the [full license terms](https://stability.ai/community-license-agreement) for more information.\r\n\r\n### Model Sources\r\n\r\nFor local or self-hosted use, we recommend [ComfyUI](https://github.com/comfyanonymous/ComfyUI) for node-based UI inference, or [diffusers](https://github.com/huggingface/diffusers) or [GitHub](https://github.com/Stability-AI/sd3.5) for programmatic use.\r\n\r\n- **ComfyUI:** [Github](https://github.com/comfyanonymous/ComfyUI), [Example Workflow](https://comfyanonymous.github.io/ComfyUI_examples/sd3/)\r\n- **Huggingface Space:** [Space](https://huggingface.co/spaces/stabilityai/stable-diffusion-3.5-large)\r\n- **Diffusers**: [See below](#using-with-diffusers).\r\n- **GitHub**: [GitHub](https://github.com/Stability-AI/sd3.5).\r\n\r\n- **API Endpoints:**\r\n  - [Stability AI API](https://platform.stability.ai/docs/api-reference#tag/Generate/paths/~1v2beta~1stable-image~1generate~1sd3/post)\r\n  - [Replicate](https://replicate.com/stability-ai/stable-diffusion-3.5-large)\r\n  - [Deepinfra](https://deepinfra.com/stabilityai/sd3.5)\r\n\r\n### Implementation Details\r\n\r\n- **QK Normalization:** Implements the QK normalization technique to improve training Stability.\r\n\r\n- **Text Encodersï¼š**\r\n    - CLIPs: [OpenCLIP-ViT/G](https://github.com/mlfoundations/open_clip), [CLIP-ViT/L](https://github.com/openai/CLIP/tree/main), context length 77 tokens\r\n    - T5: [T5-xxl](https://huggingface.co/google/t5-v1_1-xxl), context length 77/256 tokens at different stages of training\r\n\r\n- **Training Data and Strategy:**\r\n    \r\n    This model was trained on a wide variety of data, including synthetic data and filtered publicly available data. \r\n\r\nFor more technical details of the original MMDiT architecture, please refer to the [Research paper](https://stability.ai/news/stable-diffusion-3-research-paper).\r\n\r\n### Model Performance\r\n\r\nSee [blog](https://stability.ai/news/introducing-stable-diffusion-3-5) for our study about comparative performance in prompt adherence and aesthetic quality. \r\n\r\n\r\n## File Structure\r\n\r\nClick here to access the [Files and versions tab](https://huggingface.co/stabilityai/stable-diffusion-3.5-large/tree/main)\r\n\r\n### Fine-tuning\r\n\r\nPlease see the fine-tuning guide [here](https://stabilityai.notion.site/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6).\r\n\r\n\r\n## Uses\r\n\r\n### Intended Uses\r\n\r\nIntended uses include the following:\r\n* Generation of artworks and use in design and other artistic processes.\r\n* Applications in educational or creative tools.\r\n* Research on generative models, including understanding the limitations of generative models.\r\n\r\nAll uses of the model must be in accordance with our [Acceptable Use Policy](https://stability.ai/use-policy).\r\n\r\n### Out-of-Scope Uses\r\n\r\nThe model was not trained to be factual or true representations of people or events.  As such, using the model to generate such content is out-of-scope of the abilities of this model.\r\n\r\n## Safety\r\n\r\nAs part of our safety-by-design and responsible AI deployment approach, we take deliberate measures to ensure Integrity starts at the early stages of development. We implement safety measures throughout the development of our models. We have implemented safety mitigations that are intended to reduce the risk of certain harms, however we recommend that developers conduct their own testing and apply additional mitigations based on their specific use cases.  \r\nFor more about our approach to Safety, please visit our [Safety page](https://stability.ai/safety).\r\n\r\n### Integrity Evaluation\r\n\r\nOur integrity evaluation methods include structured evaluations and red-teaming testing for certain harms.  Testing was conducted primarily in English and may not cover all possible harms.  \r\n\r\n### Risks identified and mitigations:\r\n\r\n* Harmful content:  We have used filtered data sets when training our models and implemented safeguards that attempt to strike the right balance between usefulness and preventing harm. However, this does not guarantee that all possible harmful content has been removed. TAll developers and deployers should exercise caution and implement content safety guardrails based on their specific product policies and application use cases.\r\n* Misuse: Technical limitations and developer and end-user education can help mitigate against malicious applications of models. All users are required to adhere to our [Acceptable Use Policy](https://stability.ai/use-policy), including when applying fine-tuning and prompt engineering mechanisms. Please reference the Stability AI Acceptable Use Policy for information on violative uses of our products.\r\n* Privacy violations: Developers and deployers are encouraged to adhere to privacy regulations with techniques that respect data privacy.\r\n\r\n### Contact\r\n\r\nPlease report any issues with the model or contact us:\r\n\r\n* support@replicate.com\r\n* License and general: https://stability.ai/license\r\n* Enterprise license: https://stability.ai/enterprise"
    },
    {
      "id": "flux-1.1-pro-ultra",
      "name": "flux-1.1-pro-ultra",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-1.1-pro-ultra",
      "createdAt": "2024-11-06T19:13:05.091037Z",
      "runCount": 18913174,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/8121c76b-fbff-41d9-834d-c70dea9d2191/flux-ultra-cover.jpg",
      "url": "https://replicate.com/black-forest-labs/flux-1.1-pro-ultra",
      "inputSchema": {
        "raw": {
          "type": "boolean",
          "description": "Generate less processed, more natural-looking images",
          "required": false,
          "default": false,
          "isImageInput": true
        },
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "image_prompt": {
          "type": "string",
          "description": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images.",
          "required": false,
          "default": "jpg",
          "isImageInput": true
        },
        "safety_tolerance": {
          "type": "integer",
          "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "required": false,
          "default": 2
        },
        "image_prompt_strength": {
          "type": "number",
          "description": "Blend between the prompt and the image prompt.",
          "required": false,
          "default": 0.1,
          "isImageInput": true
        }
      },
      "readme": "## About\r\n\r\nA new high-resolution capabilities to FLUX1.1 [pro], extending its functionality to support 4x higher image resolutions (up to 4MP) while maintaining an impressive generation time of only 10 seconds per sample.\r\n\r\n## Higher Resolution, No Compromise in Speed\r\n\r\nFLUX1.1 [pro] â€“ ultra mode: This option enables image generation at four times the resolution of standard FLUX1.1 [pro], without sacrificing prompt adherence. Unlike many high-resolution models that experience significant slowdowns at higher resolutions, our performance benchmarks show sustained fast generation timesâ€”over 2.5x faster than comparable high-resolution offerings. This model is available at a competitive price of $0.06 per image.\r\n\r\n## Raw Mode\r\n\r\nFLUX1.1 [pro] â€“ raw mode: For creators seeking authenticity, our new raw mode captures the genuine feel of candid photography. Toggle this feature to generate images with a less synthetic, more natural aesthetic. Compared to other text-to-image models, raw mode significantly increases diversity in human subjects and enhances the realism of nature photography\r\n\r\n# License\r\n\r\nBy using FLUX.1 [pro] through Replicate you agree to the [Black Forest Labs API agreement](https://docs.bfl.ml/agreement/) and the [Black Forest Labs Terms of Service](https://blackforestlabs.ai/terms-of-service/)."
    },
    {
      "id": "flux-1.1-pro",
      "name": "flux-1.1-pro",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-1.1-pro",
      "createdAt": "2024-10-01T17:40:24.295660Z",
      "runCount": 63893766,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/bd872eff-363a-4e10-8cc1-84057afa9f57/flux-1.1-cover.webp",
      "url": "https://replicate.com/black-forest-labs/flux-1.1-pro",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "width": {
          "type": "integer",
          "description": "Width of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "required": false,
          "isImageInput": true
        },
        "height": {
          "type": "integer",
          "description": "Height of the generated image in text-to-image mode. Only used when aspect_ratio=custom. Must be a multiple of 32 (if it's not, it will be rounded to nearest multiple of 32). Note: Ignored in img2img and inpainting modes.",
          "required": false,
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "image_prompt": {
          "type": "string",
          "description": "Image to use with Flux Redux. This is used together with the text prompt to guide the generation towards the composition of the image_prompt. Must be jpeg, png, gif, or webp.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images.",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 80,
          "isImageInput": true
        },
        "safety_tolerance": {
          "type": "integer",
          "description": "Safety tolerance, 1 is most strict and 6 is most permissive",
          "required": false,
          "default": 2
        },
        "prompt_upsampling": {
          "type": "boolean",
          "description": "Automatically modify the prompt for more creative generation",
          "required": false,
          "default": false
        }
      },
      "readme": "**FLUX1.1 [pro]** provides six times faster generation than its predecessor [FLUX.1 [pro]](https://replicate.com/black-forest-labs/flux-pro) while also improving image quality, prompt adherence, and diversity.\r\n\r\n* Superior Speed and Efficiency: Faster generation times and reduced latency, enabling more efficient workflows. FLUX1.1 [pro] provides an ideal tradeoff between image quality and inference speed.\r\n* Improved Performance: FLUX1.1 [pro] has been introduced and tested under the codename \"blueberry\" into the [Artificial Analysis image arena](https://artificialanalysis.ai/text-to-image/arena), a popular benchmark for text-to-image models. It surpasses all other models on the leaderboard, achieving the highest overall Elo score.\r\n\r\nRead the announcement from Black Forest Labs [here](https://blackforestlabs.ai/announcing-flux-1-1-pro-and-the-bfl-api/).\r\n\r\nAll public FLUX.1 models are based on a hybrid architecture of [multimodal](https://arxiv.org/abs/2403.03206) and [parallel diffusion transformer](https://arxiv.org/abs/2302.05442) blocks and scaled to 12B parameters. We improve over previous state-of-the-art diffusion models by building on [flow matching](https://arxiv.org/abs/2210.02747), a general and conceptually simple method for training generative models, which includes diffusion as a special case. In addition, we increase model performance and improve hardware efficiency by incorporating [rotary positional embeddings](https://arxiv.org/abs/2104.09864) and [parallel attention layers](https://arxiv.org/abs/2302.05442).\r\n\r\n# License\r\n\r\nBy using FLUX.1 [pro] through Replicate you agree to the [Black Forest Labs API agreement](https://docs.bfl.ml/agreement/) and the [Black Forest Labs Terms of Service](https://blackforestlabs.ai/terms-of-service/)."
    },
    {
      "id": "stable-diffusion-3.5-medium",
      "name": "stable-diffusion-3.5-medium",
      "owner": "stability-ai",
      "fullName": "stability-ai/stable-diffusion-3.5-medium",
      "createdAt": "2024-10-29T12:55:45.899504Z",
      "runCount": 85447,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/d65fc397-135b-4976-a84d-12980ab2c0bc/replicate-prediction-_4kWPYZu.webp",
      "url": "https://replicate.com/stability-ai/stable-diffusion-3.5-medium",
      "inputSchema": {
        "cfg": {
          "type": "number",
          "description": "The guidance scale tells the model how similar the output should be to the prompt.",
          "required": false,
          "default": 5
        },
        "seed": {
          "type": "integer",
          "description": "Set a seed for reproducibility. Random by default.",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "Input image for image to image mode. The aspect ratio of your output will match this image.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "The aspect ratio of your output image. This value is ignored if you are using an input image.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "negative_prompt": {
          "type": "string",
          "description": "What you do not want to see in the image",
          "required": false,
          "isImageInput": true
        },
        "prompt_strength": {
          "type": "number",
          "description": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
          "required": false,
          "default": 0.85,
          "isImageInput": true
        }
      },
      "readme": "# Stable Diffusion 3.5 Medium\r\n![3.5 Medium Demo Image](https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/resolve/main/sd3.5_medium_demo.jpg)\r\n\r\n## Model\r\n\r\n![MMDiT-X](https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/resolve/main/mmdit-x.png)\r\n\r\n[Stable Diffusion 3.5 Medium](https://stability.ai/news/introducing-stable-diffusion-3-5) is a Multimodal Diffusion Transformer with improvements (MMDiT-x) text-to-image model that features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.\r\n\r\nPlease note: This model is released under the [Stability Community License](https://stability.ai/community-license-agreement). Visit [Stability AI](https://stability.ai/license) to learn or [contact us](https://stability.ai/enterprise) for commercial licensing details.\r\n\r\n\r\n### Model Description\r\n\r\n- **Developed by:** Stability AI\r\n- **Model type:** MMDiT-X text-to-image generative model\r\n- **Model Description:**  This model generates images based on text prompts. It is a Multimodal Diffusion Transformer\r\n(https://arxiv.org/abs/2403.03206) with improvements that use three fixed, pretrained text encoders, with QK-normalization to improve training stability, and dual attention blocks in the first 12 transformer layers.\r\n\r\n### License\r\n\r\n- **Community License:**  Free for research, non-commercial, and commercial use for organizations or individuals with less than $1M in total annual revenue. More details can be found in the [Community License Agreement](https://stability.ai/community-license-agreement). Read more at https://stability.ai/license.\r\n- **For individuals and organizations with annual revenue above $1M**: please [contact us](https://stability.ai/enterprise) to get an Enterprise License.\r\n\r\n### Model Sources\r\n\r\nFor local or self-hosted use, we recommend [ComfyUI](https://github.com/comfyanonymous/ComfyUI) for node-based UI inference, or [diffusers](https://github.com/huggingface/diffusers) or [GitHub](https://github.com/Stability-AI/sd3.5) for programmatic use.\r\n\r\n- **ComfyUI:** [Github](https://github.com/comfyanonymous/ComfyUI), [Example Workflow](https://comfyanonymous.github.io/ComfyUI_examples/sd3/)\r\n- **Huggingface Space:** [Space](https://huggingface.co/spaces/stabilityai/stable-diffusion-3.5-medium)\r\n- **Diffusers**: [See below](#using-with-diffusers).\r\n- **GitHub**: [GitHub](https://github.com/Stability-AI/sd3.5).\r\n\r\n- **API Endpoints:**\r\n  - [Stability AI API](https://platform.stability.ai/docs/api-reference#tag/Generate/paths/~1v2beta~1stable-image~1generate~1sd3/post)\r\n\r\n\r\n### Implementation Details\r\n\r\n- **MMDiT-X:** Introduces self-attention modules in the first 13 layers of the transformer, enhancing multi-resolution generation and overall image coherence.\r\n\r\n- **QK Normalization:** Implements the QK normalization technique to improve training Stability.\r\n\r\n- **Mixed-Resolution Training:** \r\n  - Progressive training stages: 256 â†’ 512 â†’ 768 â†’ 1024 â†’ 1440 resolution\r\n  - The final stage included mixed-scale image training to boost multi-resolution generation performance\r\n  - Extended positional embedding space to 384x384 (latent) at lower resolution stages\r\n  - Employed random crop augmentation on positional embeddings to enhance transformer layer robustness across the entire range of mixed resolutions and aspect ratios. For example, given a 64x64 latent image, we add a randomly cropped 64x64 embedding from the 192x192 embedding space during training as the input to the x stream.\r\n\r\nThese enhancements collectively contribute to the model's improved performance in multi-resolution image generation, coherence, and adaptability across various text-to-image tasks.\r\n\r\n- **Text Encodersï¼š**\r\n    - CLIPs: [OpenCLIP-ViT/G](https://github.com/mlfoundations/open_clip), [CLIP-ViT/L](https://github.com/openai/CLIP/tree/main), context length 77 tokens\r\n    - T5: [T5-xxl](https://huggingface.co/google/t5-v1_1-xxl), context length 77/256 tokens at different stages of training\r\n\r\n- **Training Data and Strategy:**\r\n    \r\n    This model was trained on a wide variety of data, including synthetic data and filtered publicly available data. \r\n\r\nFor more technical details of the original MMDiT architecture, please refer to the [Research paper](https://stability.ai/news/stable-diffusion-3-research-paper).\r\n\r\n### Usage & Limitations\r\n- While this model can handle long prompts, you may observe artifacts on the edge of generations when T5 tokens go over 256. Pay attention to the token limits when using this model in your workflow, and shortern prompts if artifacts becomes too obvious.\r\n- The medium model has a different training data distribution than the large model, so it may not respond to the same prompt similarly.\r\n- We recommended to sample with **[Skip Layer Guidance](https://github.com/comfyanonymous/ComfyUI/pull/5404)** for better struture and anatomy coherency.\r\n\r\n### Model Performance\r\n\r\nSee [blog](https://stability.ai/news/introducing-stable-diffusion-3-5) for our study about comparative performance in prompt adherence and aesthetic quality. \r\n\r\n\r\n### Fine-tuning\r\n\r\nPlease see the fine-tuning guide [here](https://stabilityai.notion.site/Stable-Diffusion-3-5-Large-Fine-tuning-Tutorial-11a61cdcd1968027a15bdbd7c40be8c6).\r\n\r\n\r\n## Uses\r\n\r\n### Intended Uses\r\n\r\nIntended uses include the following:\r\n* Generation of artworks and use in design and other artistic processes.\r\n* Applications in educational or creative tools.\r\n* Research on generative models, including understanding the limitations of generative models.\r\n\r\nAll uses of the model must be in accordance with our [Acceptable Use Policy](https://stability.ai/use-policy).\r\n\r\n### Out-of-Scope Uses\r\n\r\nThe model was not trained to be factual or true representations of people or events.  As such, using the model to generate such content is out-of-scope of the abilities of this model.\r\n\r\n## Safety\r\n\r\nAs part of our safety-by-design and responsible AI deployment approach, we take deliberate measures to ensure Integrity starts at the early stages of development. We implement safety measures throughout the development of our models. We have implemented safety mitigations that are intended to reduce the risk of certain harms, however we recommend that developers conduct their own testing and apply additional mitigations based on their specific use cases.  \r\nFor more about our approach to Safety, please visit our [Safety page](https://stability.ai/safety).\r\n\r\n### Integrity Evaluation\r\n\r\nOur integrity evaluation methods include structured evaluations and red-teaming testing for certain harms.  Testing was conducted primarily in English and may not cover all possible harms.  \r\n\r\n### Risks identified and mitigations:\r\n\r\n* Harmful content:  We have used filtered data sets when training our models and implemented safeguards that attempt to strike the right balance between usefulness and preventing harm. However, this does not guarantee that all possible harmful content has been removed. TAll developers and deployers should exercise caution and implement content safety guardrails based on their specific product policies and application use cases.\r\n* Misuse: Technical limitations and developer and end-user education can help mitigate against malicious applications of models. All users are required to adhere to our [Acceptable Use Policy](https://stability.ai/use-policy), including when applying fine-tuning and prompt engineering mechanisms. Please reference the Stability AI Acceptable Use Policy for information on violative uses of our products.\r\n* Privacy violations: Developers and deployers are encouraged to adhere to privacy regulations with techniques that respect data privacy.\r\n\r\n### Contact\r\n\r\nPlease report any issues with the model or contact us:\r\n\r\n* support@replicate.com\r\n* License and general: https://stability.ai/license\r\n* Enterprise license: https://stability.ai/enterprise"
    },
    {
      "id": "flux-schnell",
      "name": "flux-schnell",
      "owner": "black-forest-labs",
      "fullName": "black-forest-labs/flux-schnell",
      "createdAt": "2024-07-30T00:32:11.473557Z",
      "runCount": 545440994,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/67c990ba-bb67-4355-822f-2bd8c42b2f0d/flux-schnell.webp",
      "url": "https://replicate.com/black-forest-labs/flux-schnell",
      "inputSchema": {
        "seed": {
          "type": "integer",
          "description": "Random seed. Set for reproducible generation",
          "required": false
        },
        "prompt": {
          "type": "string",
          "description": "Prompt for generated image",
          "required": true,
          "isImageInput": true
        },
        "go_fast": {
          "type": "boolean",
          "description": "Run faster predictions with model optimized for speed (currently fp8 quantized); disable to run in original bf16. Note that outputs will not be deterministic when this is enabled, even if you set a seed.",
          "required": false,
          "default": true
        },
        "megapixels": {
          "type": "string",
          "description": "Approximate number of megapixels for generated image",
          "required": false,
          "default": "1",
          "isImageInput": true
        },
        "num_outputs": {
          "type": "integer",
          "description": "Number of outputs to generate",
          "required": false,
          "default": 1
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "output_quality": {
          "type": "integer",
          "description": "Quality when saving the output images, from 0 to 100. 100 is best quality, 0 is lowest quality. Not relevant for .png outputs",
          "required": false,
          "default": 80,
          "isImageInput": true
        },
        "num_inference_steps": {
          "type": "integer",
          "description": "Number of denoising steps. 4 is recommended, and lower number of steps produce lower quality outputs, faster.",
          "required": false,
          "default": 4
        },
        "disable_safety_checker": {
          "type": "boolean",
          "description": "Disable safety checker for generated images.",
          "required": false,
          "default": false,
          "isImageInput": true
        }
      },
      "readme": "![](https://tjzk.replicate.delivery/markdownx/2cc9ad85-816b-4374-b3d3-cb4f06b49c3f.jpg)\r\n\r\n`FLUX.1 [schnell]` is a 12 billion parameter rectified flow transformer capable of generating images from text descriptions.\r\nFor more information, please read our [blog post](https://blackforestlabs.ai/announcing-black-forest-labs/).\r\n\r\n# Key Features\r\n1. Cutting-edge output quality and competitive prompt following, matching the performance of closed source alternatives.\r\n2. Trained using latent adversarial diffusion distillation, `FLUX.1 [schnell]` can generate high-quality images in only 1 to 4 steps.\r\n3. Released under the `apache-2.0` licence, the model can be used for personal, scientific, and commercial purposes.\r\n\r\n# Usage\r\nWe provide a reference implementation of `FLUX.1 [schnell]`, as well as sampling code, in a dedicated [github repository](https://github.com/black-forest-labs/flux).\r\nDevelopers and creatives looking to build on top of `FLUX.1 [schnell]` are encouraged to use this as a starting point.\r\n\r\n## ComfyUI\r\n`FLUX.1 [schnell]` is also available in [Comfy UI](https://github.com/comfyanonymous/ComfyUI) for local inference with a node-based workflow.\r\n\r\n# Limitations\r\n- This model is not intended or able to provide factual information.\r\n- As a statistical model this checkpoint might amplify existing societal biases.\r\n- The model may fail to generate output that matches the prompts.\r\n- Prompt following is heavily influenced by the prompting-style.\r\n\r\n# Out-of-Scope Use\r\nThe model and its derivatives may not be used\r\n\r\n- In any way that violates any applicable national, federal, state, local or international law or regulation.\r\n- For the purpose of exploiting, harming or attempting to exploit or harm minors in any way; including but not limited to the solicitation, creation, acquisition, or dissemination of child exploitative content.\r\n- To generate or disseminate verifiably false information and/or content with the purpose of harming others.\r\n- To generate or disseminate personal identifiable information that can be used to harm an individual.\r\n- To harass, abuse, threaten, stalk, or bully individuals or groups of individuals.\r\n- To create non-consensual nudity or illegal pornographic content.\r\n- For fully automated decision making that adversely impacts an individual's legal rights or otherwise creates or modifies a binding, enforceable obligation.\r\n- Generating or facilitating large-scale disinformation campaigns.\r\n\r\n# Accelerated Inference\r\nWe provide a `go_fast` flag within the API which toggles a version of flux-schnell optimized for inference. Currently this version is a compiled fp8 quantization with an optimized attention kernel. We'll update the model and this documentation as we develop further enhancements."
    },
    {
      "id": "stable-diffusion-3.5-large-turbo",
      "name": "stable-diffusion-3.5-large-turbo",
      "owner": "stability-ai",
      "fullName": "stability-ai/stable-diffusion-3.5-large-turbo",
      "createdAt": "2024-10-22T12:09:38.705615Z",
      "runCount": 825263,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/9e1b4258-22bd-4a59-ba4a-ecac220a8a9b/replicate-prediction-_WU4XtaV.webp",
      "url": "https://replicate.com/stability-ai/stable-diffusion-3.5-large-turbo",
      "inputSchema": {
        "cfg": {
          "type": "number",
          "description": "The guidance scale tells the model how similar the output should be to the prompt.",
          "required": false,
          "default": 1
        },
        "seed": {
          "type": "integer",
          "description": "Set a seed for reproducibility. Random by default.",
          "required": false
        },
        "image": {
          "type": "string",
          "description": "Input image for image to image mode. The aspect ratio of your output will match this image.",
          "required": false,
          "format": "uri",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "The aspect ratio of your output image. This value is ignored if you are using an input image.",
          "required": false,
          "default": "1:1",
          "isImageInput": true
        },
        "output_format": {
          "type": "string",
          "description": "Format of the output images",
          "required": false,
          "default": "webp",
          "isImageInput": true
        },
        "negative_prompt": {
          "type": "string",
          "description": "What you do not want to see in the image",
          "required": false,
          "isImageInput": true
        },
        "prompt_strength": {
          "type": "number",
          "description": "Prompt strength (or denoising strength) when using image to image. 1.0 corresponds to full destruction of information in image.",
          "required": false,
          "default": 0.85,
          "isImageInput": true
        }
      },
      "readme": "# Stable Diffusion 3.5 Large Turbo\r\n![3.5 Large Turbo Demo Image](https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo/resolve/main/sd3.5_large_turbo_demo.png)\r\n\r\n## Model\r\n\r\n![MMDiT](https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo/resolve/main/mmdit.png)\r\n\r\n\r\n[Stable Diffusion 3.5 Large Turbo](https://stability.ai/news/introducing-stable-diffusion-3-5) is a  Multimodal Diffusion Transformer (MMDiT) text-to-image model with [Adversarial Diffusion Distillation (ADD)](https://stability.ai/research/adversarial-diffusion-distillation) that features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency, with a focus on fewer inference steps.\r\n\r\nPlease note: This model is released under the [Stability Community License](https://stability.ai/community-license-agreement). Visit [Stability AI](https://stability.ai/license) to learn or [contact us](https://stability.ai/enterprise) for commercial licensing details.\r\n\r\n\r\n### Model Description\r\n\r\n- **Developed by:** Stability AI\r\n- **Model type:** MMDiT text-to-image generative model\r\n- **Model Description:** This model generates images based on text prompts. It is an ADD-distilled [Multimodal Diffusion Transformer](https://arxiv.org/abs/2403.03206) that use three fixed, pretrained text encoders, and with QK-normalization. \r\n\r\n### License\r\n\r\n- **Community License:** Free for research, non-commercial, and commercial use for organizations or individuals with less than $1M in total annual revenue. More details can be found in the [Community License Agreement](https://stability.ai/community-license-agreement). Read more at https://stability.ai/license.\r\n- **For individuals and organizations with annual revenue above $1M**: Please [contact us](https://stability.ai/enterprise) to get an Enterprise License.\r\n\r\n### Model Sources\r\n\r\nFor local or self-hosted use, we recommend [ComfyUI](https://github.com/comfyanonymous/ComfyUI) for node-based UI inference, or [diffusers](https://github.com/huggingface/diffusers) or [GitHub](https://github.com/Stability-AI/sd3.5) for programmatic use.\r\n\r\n- **ComfyUI:** [Github](https://github.com/comfyanonymous/ComfyUI), [Example Workflow](https://comfyanonymous.github.io/ComfyUI_examples/sd3/)\r\n  \r\n- **Huggingface Space:** [Space](https://huggingface.co/spaces/stabilityai/stable-diffusion-3.5-large-turbo)\r\n\r\n- **Diffusers**: [See below](#using-with-diffusers).\r\n\r\n- **GitHub**: [GitHub](https://github.com/Stability-AI/sd3.5).\r\n\r\n- **API Endpoints:**\r\n  - [Stability AI API](https://platform.stability.ai/docs/api-reference#tag/Generate/paths/~1v2beta~1stable-image~1generate~1sd3/post)\r\n  - [Deepinfra](https://deepinfra.com/stabilityai/sd3.5)\r\n\r\n\r\n\r\n### Implementation Details\r\n\r\n- **QK Normalization:** Implements the QK normalization technique to improve training Stability.\r\n\r\n- **Adversarial Diffusion Distillation (ADD)** (see the [technical report](https://stability.ai/research/adversarial-diffusion-distillation)), which allows sampling with 4 steps at high image quality. \r\n\r\n- **Text Encodersï¼š**\r\n    - CLIPs: [OpenCLIP-ViT/G](https://github.com/mlfoundations/open_clip), [CLIP-ViT/L](https://github.com/openai/CLIP/tree/main), context length 77 tokens\r\n    - T5: [T5-xxl](https://huggingface.co/google/t5-v1_1-xxl), context length 77/256 tokens at different stages of training\r\n\r\n- **Training Data and Strategy:**\r\n    \r\n    This model was trained on a wide variety of data, including synthetic data and filtered publicly available data. \r\n\r\nFor more technical details of the original MMDiT architecture, please refer to the [Research paper](https://stability.ai/news/stable-diffusion-3-research-paper).\r\n\r\n\r\n### Model Performance\r\n\r\nSee [blog](https://stability.ai/news/introducing-stable-diffusion-3-5) for our study about comparative performance in prompt adherence and aesthetic quality. \r\n\r\n\r\n## File Structure\r\n\r\nClick here to access the [Files and versions tab](https://huggingface.co/stabilityai/stable-diffusion-3.5-large-turbo/tree/main)\r\n\r\n\r\n## Uses\r\n\r\n### Intended Uses\r\n\r\nIntended uses include the following:\r\n* Generation of artworks and use in design and other artistic processes.\r\n* Applications in educational or creative tools.\r\n* Research on generative models, including understanding the limitations of generative models.\r\n\r\nAll uses of the model must be in accordance with our [Acceptable Use Policy](https://stability.ai/use-policy).\r\n\r\n### Out-of-Scope Uses\r\n\r\nThe model was not trained to be factual or true representations of people or events.  As such, using the model to generate such content is out-of-scope of the abilities of this model.\r\n\r\n## Safety\r\n\r\nAs part of our safety-by-design and responsible AI deployment approach, we take deliberate measures to ensure Integrity starts at the early stages of development. We implement safety measures throughout the development of our models. We have implemented safety mitigations that are intended to reduce the risk of certain harms, however we recommend that developers conduct their own testing and apply additional mitigations based on their specific use cases.  \r\nFor more about our approach to Safety, please visit our [Safety page](https://stability.ai/safety).\r\n\r\n### Integrity Evaluation\r\n\r\nOur integrity evaluation methods include structured evaluations and red-teaming testing for certain harms.  Testing was conducted primarily in English and may not cover all possible harms.  \r\n\r\n### Risks identified and mitigations:\r\n\r\n* Harmful content:  We have used filtered data sets when training our models and implemented safeguards that attempt to strike the right balance between usefulness and preventing harm. However, this does not guarantee that all possible harmful content has been removed. TAll developers and deployers should exercise caution and implement content safety guardrails based on their specific product policies and application use cases.\r\n* Misuse: Technical limitations and developer and end-user education can help mitigate against malicious applications of models. All users are required to adhere to our [Acceptable Use Policy](https://stability.ai/use-policy), including when applying fine-tuning and prompt engineering mechanisms. Please reference the Stability AI Acceptable Use Policy for information on violative uses of our products.\r\n* Privacy violations: Developers and deployers are encouraged to adhere to privacy regulations with techniques that respect data privacy.\r\n\r\n## Contact\r\n\r\nPlease report any issues with the model or contact us:\r\n\r\n* support@replicate.com\r\n* License and general: https://stability.ai/license\r\n* Enterprise license: https://stability.ai/enterprise"
    },
    {
      "id": "recraft-v3",
      "name": "recraft-v3",
      "owner": "recraft-ai",
      "fullName": "recraft-ai/recraft-v3",
      "createdAt": "2024-10-30T12:41:06.099624Z",
      "runCount": 6937612,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/a2b66c42-4633-443d-997f-cc987bca07c7/V3.webp",
      "url": "https://replicate.com/recraft-ai/recraft-v3",
      "inputSchema": {
        "size": {
          "type": "string",
          "description": "Width and height of the generated image. Size is ignored if an aspect ratio is set.",
          "required": false,
          "default": "1024x1024",
          "isImageInput": true
        },
        "style": {
          "type": "string",
          "description": "Style of the generated image.",
          "required": false,
          "default": "any",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "Not set",
          "isImageInput": true
        }
      },
      "readme": "## Overview\r\n\r\nRecraft introduces a revolutionary AI model that thinks in design language. This new model has set a new standard for excellence in image generation and follows a period of rapid growth for the graphic design platform. Since its launch in 2023, Recraft has been used by over 3 million users in more than 200 countries.\r\n\r\n## Model Features\r\n\r\n- **Improved image generation** quality through superior prompt understanding, leading to more accurate visual representations of the designerâ€™s intent. As a result, designers gain enhanced visual aesthetics, improving anatomy and overall image quality. Image generation quality of the latest model is better than all existing image generation models proven by [public benchmarks](https://huggingface.co/spaces/ArtificialAnalysis/Text-to-Image-Leaderboard)\r\n- **Accurate text generation** in images. Recraftâ€™s new model is the first to offer image generation with text of any size and length. This feature sets it apart from others â€” while very few models can offer similar capabilities, they still canâ€™t match Recraftâ€™s ability to generate long texts within an image.\r\n- **A unique graphic design generator** that enables seamless and precise integration of text and image elements into AI-generated designs. It is now possible to set the exact positions of text and different elements in the image instead of interpreting the explanation in the prompt to get the needed result - just drag and drop images into frames and use the modelâ€™s controlled AI generation to ensure their vision comes to life strictly as intended.\r\n- **Brand style customization** feature allows users to upload reference images for the AI to generate branded content. The new style creation flow allows for fine-grained experimentation with style details to get exactly the style required for the brand's unique look and feel.\r\n- **Recraftâ€™s model supports both raster and vector image generation.** It stands out from AI generators like MidJourney and OpenAI because their models don't support the ability to generate vector art. Apart from that, Recraft V3 supports an extensive list of AI image editing tools.\r\n\r\n## Team Expertise\r\n\r\nThe team behind Recraft brings extensive machine-learning expertise and experience to the graphic design industry. Founder Anna Veronika Dorogush is the creator of [CatBoost](https://catboost.ai), one of the most popular Machine Learning frameworks in the world, with hundreds of thousands of weekly downloads.\r\n\r\n\r\n## Licensing and commercial use\r\n\r\nIf you generate images on Replicate with Recraft-v3 models, then you can use the images commercially."
    },
    {
      "id": "recraft-v3-svg",
      "name": "recraft-v3-svg",
      "owner": "recraft-ai",
      "fullName": "recraft-ai/recraft-v3-svg",
      "createdAt": "2024-10-30T13:59:33.006694Z",
      "runCount": 314073,
      "isOfficial": true,
      "coverImageUrl": "https://tjzk.replicate.delivery/models_models_featured_image/223c73a9-0347-4daa-9710-3878f95479e3/svg-cover.webp",
      "url": "https://replicate.com/recraft-ai/recraft-v3-svg",
      "inputSchema": {
        "size": {
          "type": "string",
          "description": "Width and height of the generated image. Size is ignored if an aspect ratio is set.",
          "required": false,
          "default": "1024x1024",
          "isImageInput": true
        },
        "style": {
          "type": "string",
          "description": "Style of the generated image.",
          "required": false,
          "default": "any",
          "isImageInput": true
        },
        "prompt": {
          "type": "string",
          "description": "Text prompt for image generation",
          "required": true,
          "isImageInput": true
        },
        "aspect_ratio": {
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "required": false,
          "default": "Not set",
          "isImageInput": true
        }
      },
      "readme": "## Overview\r\n\r\nRecraft introduces a revolutionary AI model that thinks in design language. This new model has set a new standard for excellence in image generation and follows a period of rapid growth for the graphic design platform. Since its launch in 2023, Recraft has been used by over 3 million users in more than 200 countries.\r\n\r\n## Model Features\r\n\r\n- **Improved image generation** quality through superior prompt understanding, leading to more accurate visual representations of the designerâ€™s intent. As a result, designers gain enhanced visual aesthetics, improving anatomy and overall image quality. Image generation quality of the latest model is better than all existing image generation models proven by [public benchmarks](https://huggingface.co/spaces/ArtificialAnalysis/Text-to-Image-Leaderboard)\r\n- **Accurate text generation** in images. Recraftâ€™s new model is the first to offer image generation with text of any size and length. This feature sets it apart from others â€” while very few models can offer similar capabilities, they still canâ€™t match Recraftâ€™s ability to generate long texts within an image.\r\n- **A unique graphic design generator** that enables seamless and precise integration of text and image elements into AI-generated designs. It is now possible to set the exact positions of text and different elements in the image instead of interpreting the explanation in the prompt to get the needed result - just drag and drop images into frames and use the modelâ€™s controlled AI generation to ensure their vision comes to life strictly as intended.\r\n- **Brand style customization** feature allows users to upload reference images for the AI to generate branded content. The new style creation flow allows for fine-grained experimentation with style details to get exactly the style required for the brand's unique look and feel.\r\n- **Recraftâ€™s model supports both raster and vector image generation.** It stands out from AI generators like MidJourney and OpenAI because their models don't support the ability to generate vector art. Apart from that, Recraft V3 supports an extensive list of AI image editing tools.\r\n\r\n## Team Expertise\r\n\r\nThe team behind Recraft brings extensive machine-learning expertise and experience to the graphic design industry. Founder Anna Veronika Dorogush is the creator of [CatBoost](https://catboost.ai), one of the most popular Machine Learning frameworks in the world, with hundreds of thousands of weekly downloads.\r\n\r\n\r\n## Licensing and commercial use\r\n\r\nIf you generate images on Replicate with Recraft-v3 models, then you can use the images commercially."
    }
  ]
}